{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yoan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"RicoBorra/DREAM-t5-small\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"RicoBorra/DREAM-t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad> A man is running after a thief.</s>'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = \"A man is running after a thief. love\"\n",
    "t = tokenizer(i, return_tensors='pt').input_ids\n",
    "o = model.generate(t, max_new_tokens = 100)\n",
    "d = tokenizer.decode(o[0])\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests on FLUTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea here was to see if it is possible to type a figurative (here sarcastic) sentence by comparing their BERTscore similarity with serious sentences and their sarcastic equivalent, drawn from the FLUTE dataset. We might expect the similiarity tends to be higher between sarcastic sentences and inversely.\n",
    "--> After testing this idea, it clearly doesn't work (On 100 random samples, the classifier detected sarcasm with only 36% accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "path = \"D:\\Documents\\PoliTo\\Deep NLP\\Project\\FLUTE-Dataset\\model-in-the-loop-fig-lang-main\\\\\"\n",
    "for type, file in {'Sarcasm' : 'SarcasmNLI\\sarcasm_train.jsonl',\n",
    "                   'Simile' : 'simileNLI\\simile_train.jsonl', \n",
    "                   'Idiom' : 'idiomNLI\\idiom_train.jsonl',\n",
    "                   'Metaphor' : 'metaphorNLI\\metaphor_train.jsonl'}.items() :\n",
    "\n",
    "    with open(path + file, 'r', encoding='utf8') as f :\n",
    "        typed_dataset = []\n",
    "        for line in f :\n",
    "            typed_dataset.append(json.loads(line))\n",
    "    for row in typed_dataset :\n",
    "        dataset.append([row['premise'], row['hypothesis'], row['label'], row['explanation'], type])\n",
    "\n",
    "dataset = pd.DataFrame(dataset, columns=['Sentence1', 'Sentence2', 'Label', 'Explanation', 'Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence1</th>\n",
       "      <th>Sentence2</th>\n",
       "      <th>Label</th>\n",
       "      <th>Explanation</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3388</th>\n",
       "      <td>I get why they would stay away from her if she...</td>\n",
       "      <td>i'd understand if they stayed away from her be...</td>\n",
       "      <td>Entailment</td>\n",
       "      <td>A coyote is a wild animal that is known to be ...</td>\n",
       "      <td>Simile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1939</th>\n",
       "      <td>I was upset to find emails between my ex wife ...</td>\n",
       "      <td>I was absolutely destroyed to find emails betw...</td>\n",
       "      <td>Entailment</td>\n",
       "      <td>Being cheated on is one of the most painful th...</td>\n",
       "      <td>Sarcasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>I crashed my favorite classic car which I've h...</td>\n",
       "      <td>I totally wrecked my favorite classic car that...</td>\n",
       "      <td>Entailment</td>\n",
       "      <td>To crash a car is to cause significant damage ...</td>\n",
       "      <td>Sarcasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>I'm waiting on some test results from the Dr. ...</td>\n",
       "      <td>I'm anxiously waiting for my test results from...</td>\n",
       "      <td>Entailment</td>\n",
       "      <td>It is common to feel anxious while waiting for...</td>\n",
       "      <td>Sarcasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3137</th>\n",
       "      <td>I had to have some tests run due to an unclear...</td>\n",
       "      <td>Having to get some tests done because of an un...</td>\n",
       "      <td>Contradiction</td>\n",
       "      <td>Having to get some tests done because of an un...</td>\n",
       "      <td>Sarcasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>I ate a box of donuts yesterday when I promise...</td>\n",
       "      <td>I feel terrible about eating a box of donuts w...</td>\n",
       "      <td>Entailment</td>\n",
       "      <td>Cheating on a diet often leads to feelings of ...</td>\n",
       "      <td>Sarcasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>I heard a knock on my door at 2 am in the morn...</td>\n",
       "      <td>I heard a knock on my door at 2 am in the morn...</td>\n",
       "      <td>Contradiction</td>\n",
       "      <td>Unknown people knocking on someone's door at 2...</td>\n",
       "      <td>Sarcasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>Once I went into a store only to realize that ...</td>\n",
       "      <td>The time I went into a store wearing two diffe...</td>\n",
       "      <td>Entailment</td>\n",
       "      <td>It is considered very sloppy and unprofessiona...</td>\n",
       "      <td>Sarcasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5387</th>\n",
       "      <td>I know its not really an excuse, but that was ...</td>\n",
       "      <td>I know its not really an excuse, but that was ...</td>\n",
       "      <td>Contradiction</td>\n",
       "      <td>To lead to believe means to cause one to belie...</td>\n",
       "      <td>Idiom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3420</th>\n",
       "      <td>She is so damn untouchable</td>\n",
       "      <td>She is like a rare stone in a museum surrounde...</td>\n",
       "      <td>Entailment</td>\n",
       "      <td>A rare stone in a museum is something that is ...</td>\n",
       "      <td>Simile</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7534 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Sentence1  \\\n",
       "3388  I get why they would stay away from her if she...   \n",
       "1939  I was upset to find emails between my ex wife ...   \n",
       "1142  I crashed my favorite classic car which I've h...   \n",
       "985   I'm waiting on some test results from the Dr. ...   \n",
       "3137  I had to have some tests run due to an unclear...   \n",
       "...                                                 ...   \n",
       "1334  I ate a box of donuts yesterday when I promise...   \n",
       "795   I heard a knock on my door at 2 am in the morn...   \n",
       "830   Once I went into a store only to realize that ...   \n",
       "5387  I know its not really an excuse, but that was ...   \n",
       "3420                         She is so damn untouchable   \n",
       "\n",
       "                                              Sentence2          Label  \\\n",
       "3388  i'd understand if they stayed away from her be...     Entailment   \n",
       "1939  I was absolutely destroyed to find emails betw...     Entailment   \n",
       "1142  I totally wrecked my favorite classic car that...     Entailment   \n",
       "985   I'm anxiously waiting for my test results from...     Entailment   \n",
       "3137  Having to get some tests done because of an un...  Contradiction   \n",
       "...                                                 ...            ...   \n",
       "1334  I feel terrible about eating a box of donuts w...     Entailment   \n",
       "795   I heard a knock on my door at 2 am in the morn...  Contradiction   \n",
       "830   The time I went into a store wearing two diffe...     Entailment   \n",
       "5387  I know its not really an excuse, but that was ...  Contradiction   \n",
       "3420  She is like a rare stone in a museum surrounde...     Entailment   \n",
       "\n",
       "                                            Explanation     Type  \n",
       "3388  A coyote is a wild animal that is known to be ...   Simile  \n",
       "1939  Being cheated on is one of the most painful th...  Sarcasm  \n",
       "1142  To crash a car is to cause significant damage ...  Sarcasm  \n",
       "985   It is common to feel anxious while waiting for...  Sarcasm  \n",
       "3137  Having to get some tests done because of an un...  Sarcasm  \n",
       "...                                                 ...      ...  \n",
       "1334  Cheating on a diet often leads to feelings of ...  Sarcasm  \n",
       "795   Unknown people knocking on someone's door at 2...  Sarcasm  \n",
       "830   It is considered very sloppy and unprofessiona...  Sarcasm  \n",
       "5387  To lead to believe means to cause one to belie...    Idiom  \n",
       "3420  A rare stone in a museum is something that is ...   Simile  \n",
       "\n",
       "[7534 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "bertscore = load(\"bertscore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarcasm_dataset = dataset[np.logical_and(dataset['Type'] == 'Sarcasm', dataset['Label'] == 'Contradiction')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8625892686843872"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = ['I truly love being crushed by a bunch of elephants' for _ in range(50)]\n",
    "ref = np.array(sarcasm_dataset['Sentence1'][50:100])\n",
    "np.mean(bertscore.compute(predictions = pred, references = ref, lang=\"en\")['precision'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [05:51<00:00,  7.03s/it]\n",
      "100%|██████████| 50/50 [05:52<00:00,  7.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 64 0.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "\n",
    "def test_sarcasm_similarity(sarcasm_train_dataset, sarcasm_test_dataset) :\n",
    "    true_sarcasm_dataset = sarcasm_test_dataset[sarcasm_test_dataset['Label'] == 'Contradiction']\n",
    "    good_predictions = 0\n",
    "    bad_predictions = 0\n",
    "    # First, test every serious sentence\n",
    "    for serious_sentence in tqdm(true_sarcasm_dataset.sample(frac=1)['Sentence1'][:50]) :\n",
    "        # Shuffle dataset at each iteration\n",
    "        sarcasm_train_dataset.sample(frac=1)\n",
    "        pred = np.array([serious_sentence for _ in range(50)])\n",
    "        ref1 = np.array(sarcasm_train_dataset['Sentence1'][:50])\n",
    "        mean1 = np.mean(bertscore.compute(predictions = pred, references = ref1, lang=\"en\")['precision'])\n",
    "        ref2 = np.array(sarcasm_train_dataset['Sentence2'][:50])\n",
    "        mean2 = np.mean(bertscore.compute(predictions=pred, references=ref2, lang='en')['precision'])\n",
    "        # If mean1 > mean2, the model would consider the sentence to be serious as it is more similar to serious sentences than sarcastic ones\n",
    "        if mean1 > mean2 :\n",
    "            good_predictions += 1\n",
    "        else :\n",
    "            bad_predictions += 1\n",
    "    # Then, test every sarcastic sentence\n",
    "    for sarcastic_sentence in tqdm(true_sarcasm_dataset.sample(frac=1)['Sentence2'][:50]) :\n",
    "        # Shuffle dataset at each iteration\n",
    "        sarcasm_train_dataset.sample(frac=1)\n",
    "        pred = np.array([serious_sentence for _ in range(50)])\n",
    "        ref1 = np.array(sarcasm_train_dataset['Sentence1'][:50])\n",
    "        mean1 = np.mean(bertscore.compute(predictions = pred, references = ref1, lang=\"en\")['precision'])\n",
    "        ref2 = np.array(sarcasm_train_dataset['Sentence2'][:50])\n",
    "        mean2 = np.mean(bertscore.compute(predictions=pred, references=ref2, lang='en')['precision'])\n",
    "        if mean2 > mean1 :\n",
    "            good_predictions += 1\n",
    "        else :\n",
    "            bad_predictions += 1\n",
    "    \n",
    "    final_precision = good_predictions / (good_predictions + bad_predictions)\n",
    "    return good_predictions, bad_predictions, final_precision\n",
    "\n",
    "with open(path + 'testgolddata\\sarcasm_test.jsonl') as f :\n",
    "    test_dataset = []\n",
    "    for line in f :\n",
    "        row = json.loads(line)\n",
    "        test_dataset.append([row['premise'], row['hypothesis'], row['label']])\n",
    "test_dataset = pd.DataFrame(test_dataset, columns=['Sentence1', 'Sentence2', 'Label'])\n",
    "\n",
    "good, bad, precision = test_sarcasm_similarity(sarcasm_dataset, test_dataset)\n",
    "print(good, bad, precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
