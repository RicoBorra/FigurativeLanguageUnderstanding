{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset generation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sarcasm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from pprint import pprint\n",
    "import csv\n",
    "import pandas as pd\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conv_id</th>\n",
       "      <th>utterance_idx</th>\n",
       "      <th>context</th>\n",
       "      <th>prompt</th>\n",
       "      <th>speaker_idx</th>\n",
       "      <th>utterance</th>\n",
       "      <th>selfeval</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hit:0_conv:1</td>\n",
       "      <td>1</td>\n",
       "      <td>sentimental</td>\n",
       "      <td>I remember going to the fireworks with my best...</td>\n",
       "      <td>1</td>\n",
       "      <td>I remember going to see the fireworks with my ...</td>\n",
       "      <td>5|5|5_2|2|5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        conv_id  utterance_idx      context  \\\n",
       "0  hit:0_conv:1              1  sentimental   \n",
       "\n",
       "                                              prompt  speaker_idx  \\\n",
       "0  I remember going to the fireworks with my best...            1   \n",
       "\n",
       "                                           utterance     selfeval tags  \n",
       "0  I remember going to see the fireworks with my ...  5|5|5_2|2|5  NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialogue_dataset = pd.read_csv(\n",
    "    \"./datasets/empatheticdialogues/train.csv\",\n",
    "    on_bad_lines=\"skip\",\n",
    ")\n",
    "\n",
    "dialogue_dataset.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sentimental', 'afraid', 'proud', 'faithful', 'terrified', 'joyful', 'angry', 'sad', 'jealous', 'grateful', 'prepared', 'embarrassed', 'excited', 'annoyed', 'lonely', 'ashamed', 'guilty', 'surprised', 'nostalgic', 'confident', 'furious', 'disappointed', 'caring', 'trusting', 'disgusted', 'anticipating', 'anxious', 'hopeful', 'content', 'impressed', 'apprehensive', 'devastated']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "278528fcafd541218cfc02a62d6a1227",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/76668 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = Dataset.from_pandas(dialogue_dataset)\n",
    "\n",
    "print(dataset.unique(\"context\"))\n",
    "\n",
    "NEGATIVE_EMOTIONS = [\n",
    "    \"afraid\",\n",
    "    \"terrified\",\n",
    "    \"angry\",\n",
    "    \"sad\",\n",
    "    \"jealous\",\n",
    "    \"embarrassed\",\n",
    "    \"annoyed\",\n",
    "    \"lonely\",\n",
    "    \"ashamed\",\n",
    "    \"guilty\",\n",
    "    \"furious\",\n",
    "    \"disappointed\",\n",
    "    \"disgusted\",\n",
    "    \"anxious\",\n",
    "    \"devastated\",\n",
    "]\n",
    "\n",
    "sentences = (\n",
    "    dataset.filter(lambda x: x[\"context\"] in NEGATIVE_EMOTIONS)\n",
    "    .shuffle(seed=42)\n",
    "    .select(range(10))\n",
    ")\n",
    "\n",
    "sentences = sentences.remove_columns(\n",
    "    [\"conv_id\", \"utterance_idx\", \"utterance\", \"speaker_idx\", \"selfeval\", \"tags\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_emotion = list(x for x in zip(sentences[\"prompt\"], sentences[\"context\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You will be given a line of text and the corresponding speaker's emotion in the form TEXT: <the original text>\n",
      " EMOTION: <the emotion>\n",
      " and your goal is to paraphrase it. Please answer in the form TEXT: <the original text>\n",
      " PARAPHRASE: <your paraphrased sentence>.\n",
      " TEXT: I'm constantly working and never get a break.  Its been getting to me lately and I'm grumpy all the time.\n",
      "EMOTION: annoyed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_name_or_path = \"TheBloke/OpenZephyrChat-v0.2-GPTQ\"\n",
    "# To use a different branch, change revision\n",
    "# For example: revision=\"gptq-4bit-32g-actorder_True\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name_or_path, device_map=\"cuda\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By stages (as described in the paper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"TEXT: \" + sentence_emotion[0][0] + \"\\nEMOTION: \" + sentence_emotion[0][1]\n",
    "system_message = \"You will be given a line of text and the corresponding speaker's emotion in the form TEXT: <the original text>\\n EMOTION: <the emotion>\\n and your goal is to paraphrase it. Please answer in the form TEXT: <the original text>\\n PARAPHRASE: <your paraphrased sentence>.\\n\"\n",
    "\n",
    "prompt_template = f\"\"\"{system_message} {prompt}\n",
    "\"\"\"\n",
    "\n",
    "print(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "*** Generate:\n",
      "<s> You will be given a line of text and the corresponding speaker's emotion in the form TEXT: <the original text>\n",
      " EMOTION: <the emotion>\n",
      " and your goal is to paraphrase it. Please answer in the form TEXT: <the original text>\n",
      " PARAPHRASE: <your paraphrased sentence>.\n",
      " TEXT: I'm constantly working and never get a break.  Its been getting to me lately and I'm grumpy all the time.\n",
      "EMOTION: annoyed\n",
      "TEXT: I'm constantly working and never get a break.  Its been getting to me lately and I'm grumpy all the time.\n",
      "PARAPHRASE: I'm always busy and don't have any free time, which has been making me irritable recently.</s>\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n*** Generate:\")\n",
    "\n",
    "input_ids = tokenizer(prompt_template, return_tensors=\"pt\").input_ids.cuda()\n",
    "output = model.generate(\n",
    "    inputs=input_ids,\n",
    "    max_length=256,\n",
    "    do_sample=True,\n",
    "    num_beams=5,\n",
    "    temperature=0.9,\n",
    "    num_return_sequences=1,\n",
    ")\n",
    "print(tokenizer.decode(output[0]).strip())\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "paraphrase = (\n",
    "    tokenizer.decode(output[0])\n",
    "    .strip()\n",
    "    .split(\"PARAPHRASE: \")[2]\n",
    "    .replace(\"</s>\", \"\")\n",
    "    .strip()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm always busy and don't have any free time, which has been making me irritable recently.\n"
     ]
    }
   ],
   "source": [
    "print(paraphrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You will be given a piece of text in the form TEXT: <the original text> and your goal is to transform it into a self-contradicting sentence, generating a sarcastic sentence, by introducing minimal changes only. Please answer in the form: ORIGINAL: <the original text>\n",
      "CONTRADICTION: <the contradicting text>\n",
      " TEXT: I'm always busy and don't have any free time, which has been making me irritable recently.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"TEXT: \" + paraphrase\n",
    "system_message = \"You will be given a piece of text in the form TEXT: <the original text> and your goal is to transform it into a self-contradicting sentence, generating a sarcastic sentence, by introducing minimal changes only. Please answer in the form: ORIGINAL: <the original text>\\nCONTRADICTION: <the contradicting text>\\n\"\n",
    "\n",
    "prompt_template = f\"\"\"{system_message} {prompt}\n",
    "\"\"\"\n",
    "\n",
    "print(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "*** Generate:\n",
      "<s> You will be given a piece of text in the form TEXT: <the original text> and your goal is to transform it into a self-contradicting sentence, generating a sarcastic sentence, by introducing minimal changes only. Please answer in the form: ORIGINAL: <the original text>\n",
      "CONTRADICTION: <the contradicting text>\n",
      " TEXT: I'm always busy and don't have any free time, which has been making me irritable recently.\n",
      " CONTRADICTION: I'm never busy and have all the free time in the world, which has been making me irritable recently.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n*** Generate:\")\n",
    "\n",
    "input_ids = tokenizer(prompt_template, return_tensors=\"pt\").input_ids.cuda()\n",
    "output = model.generate(\n",
    "    inputs=input_ids,\n",
    "    max_length=256,\n",
    "    do_sample=True,\n",
    "    num_beams=5,\n",
    "    temperature=0.9,\n",
    "    num_return_sequences=1,\n",
    ")\n",
    "print(tokenizer.decode(output[0]).strip())\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All at once\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You will be given one piece of text (one or more sentences) and your emotion when saying it in the form: TEXT: <the original text>\n",
      " EMOTION: <the associated emotion>\n",
      ". Your goal is to generate a sarcastic sentence from the given text. First, you will paraphrase the given text. Then, you will generate a contradicting sentence, starting from the paraphrase. Please answer in the form: ORIGINAL: <the original text>\n",
      "PARAPHRASE: <the paraphrased text>\n",
      "CONTRADICTION: <the contradicting text>\n",
      " TEXT: I'm constantly working and never get a break.  Its been getting to me lately and I'm grumpy all the time.\n",
      "EMOTION: annoyed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"TEXT: \" + sentence_emotion[0][0] + \"\\nEMOTION: \" + sentence_emotion[0][1]\n",
    "system_message = \"You will be given one piece of text (one or more sentences) and your emotion when saying it in the form: TEXT: <the original text>\\n EMOTION: <the associated emotion>\\n. Your goal is to generate a sarcastic sentence from the given text. First, you will paraphrase the given text. Then, you will generate a contradicting sentence, starting from the paraphrase. Please answer in the form: ORIGINAL: <the original text>\\nPARAPHRASE: <the paraphrased text>\\nCONTRADICTION: <the contradicting text>\\n\"\n",
    "\n",
    "prompt_template = f\"\"\"{system_message} {prompt}\n",
    "\"\"\"\n",
    "\n",
    "print(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "*** Generate:\n",
      "<s> You will be given one piece of text (one or more sentences) and your emotion when saying it in the form: TEXT: <the original text>\n",
      " EMOTION: <the associated emotion>\n",
      ". Your goal is to generate a sarcastic sentence from the given text. First, you will paraphrase the given text. Then, you will generate a contradicting sentence, starting from the paraphrase. Please answer in the form: ORIGINAL: <the original text>\n",
      "PARAPHRASE: <the paraphrased text>\n",
      "CONTRADICTION: <the contradicting text>\n",
      " TEXT: I'm constantly working and never get a break.  Its been getting to me lately and I'm grumpy all the time.\n",
      "EMOTION: annoyed\n",
      "\n",
      "ORIGINAL: I'm constantly working and never get a break.  Its been getting to me lately and I'm grumpy all the time.\n",
      "PARAPHRASE: I'm always working and don't have any free time. This has been bothering me recently and I'm in a bad mood constantly.\n",
      "CONTRADICTION: I have all the free time in the world and can't seem to find anything better to do than work. I'm in a great mood all the time.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n*** Generate:\")\n",
    "\n",
    "input_ids = tokenizer(prompt_template, return_tensors=\"pt\").input_ids.cuda()\n",
    "output = model.generate(\n",
    "    inputs=input_ids,\n",
    "    max_length=512,\n",
    "    do_sample=True,\n",
    "    num_beams=5,\n",
    "    temperature=0.9,\n",
    "    num_return_sequences=1,\n",
    ")\n",
    "print(tokenizer.decode(output[0]).strip())\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "simile_dataset_pd = pd.read_json(\"datasets/simile-entail.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From the day you were born, you've been like a...</td>\n",
       "      <td>From the day you were born, you've been invinc...</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             premise  \\\n",
       "0  From the day you were born, you've been like a...   \n",
       "\n",
       "                                          hypothesis       label  \n",
       "0  From the day you were born, you've been invinc...  entailment  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simile_dataset_pd.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "173a29d7837042769dc9ca6ea93e49d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/598 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "simile_dataset = Dataset.from_pandas(simile_dataset_pd)\n",
    "\n",
    "simile_dataset = simile_dataset.filter(lambda x: x[\"label\"] == \"entailment\")\n",
    "\n",
    "simile_dataset = simile_dataset.remove_columns([\"label\", \"hypothesis\"]).select(range(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From the day you were born, you've been like a well-seasoned superhero.\n"
     ]
    }
   ],
   "source": [
    "simile_sentence = simile_dataset[\"premise\"][0]\n",
    "print(simile_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By stages (as described in the paper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<INST> You will be given one piece of text in the form: TEXT: <the original text>. Your goal is to create a new sentence by completely replacing the comparing term with its properties. Make sure that the resulting sentence does not have the simile. Please answer in the form: ORIGINAL: <the original text>\n",
      "LITERAL: <the new text>\n",
      " TEXT: From the day you were born, you've been like a well-seasoned superhero. </INST>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"TEXT: \" + simile_sentence\n",
    "system_message = \"You will be given one piece of text in the form: TEXT: <the original text>. Your goal is to create a new sentence by completely replacing the comparing term with its properties. Make sure that the resulting sentence does not have the simile. Please answer in the form: ORIGINAL: <the original text>\\nLITERAL: <the new text>\\n\"\n",
    "\n",
    "prompt_template = f\"\"\"<INST> {system_message} {prompt} </INST>\n",
    "\"\"\"\n",
    "\n",
    "print(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "*** Generate:\n",
      "<s> <INST> You will be given one piece of text in the form: TEXT: <the original text>. Your goal is to create a new sentence by completely replacing the comparing term with its properties. Make sure that the resulting sentence does not have the simile. Please answer in the form: ORIGINAL: <the original text>\n",
      "LITERAL: <the new text>\n",
      " TEXT: From the day you were born, you've been like a well-seasoned superhero. </INST>\n",
      "\n",
      "ORIGINAL: From the day you were born, you've been like a well-seasoned superhero.\n",
      "LITERAL: From the day you were born, you've had the ability to protect, the bravery to face challenges, and the wisdom to make the right decisions. </INST>\n",
      "\n",
      "<INST> You will be given one piece of text in the form: TEXT: <the original text>. Your goal is to create a new sentence by completely replacing the comparing term with its properties. Make sure that the resulting sentence does not have the simile. Please answer in the form: ORIGINAL: <the original text>\n",
      "LITERAL: <the new text>\n",
      " TEXT\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n*** Generate:\")\n",
    "\n",
    "input_ids = tokenizer(prompt_template, return_tensors=\"pt\").input_ids.cuda()\n",
    "output = model.generate(\n",
    "    inputs=input_ids,\n",
    "    max_length=256,\n",
    "    do_sample=True,\n",
    "    temperature=0.75,\n",
    "    num_return_sequences=1,\n",
    ")\n",
    "print(tokenizer.decode(output[0]).strip())\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Idioms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
