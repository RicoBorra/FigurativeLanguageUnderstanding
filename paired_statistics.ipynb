{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from datasets import Dataset, DatasetDict, load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Trainer\n",
    "import pandas as pd\n",
    "import torch\n",
    "import evaluate\n",
    "import os\n",
    "\n",
    "BATCH_SIZE = 12\n",
    "NUM_EPOCHS = 8\n",
    "N_GEN = 50\n",
    "base_checkpoint = \"t5-small\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_checkpoint)\n",
    "\n",
    "#ds = load_dataset(\"ColumbiaNLP/FLUTE\").shuffle(seed=42)\n",
    "df = pd.read_csv(\"complete_dataset.csv\").fillna(\"\")\n",
    "ds = Dataset.from_pandas(df).shuffle(seed=42)\n",
    "folds = StratifiedKFold(n_splits=10, shuffle=False)\n",
    "splits = folds.split(ds, ds['label'])\n",
    "indexes = [t for t in splits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70cdf3ecf4a24803888a6856c6a15950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7534 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from flute_dream import add_combined_cols\n",
    "\n",
    "ds = ds.map(add_combined_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset_s1(examples):\n",
    "    model_inputs = tokenizer(examples['premise_hypothesis'])\n",
    "    labels = tokenizer(examples['label_explanation'])\n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "    return model_inputs\n",
    "\n",
    "def preprocess_dataset_s2(examples):\n",
    "    model_inputs = tokenizer(examples['premise_hypothesis_system_2'])\n",
    "    labels = tokenizer(examples['type_label_explanation'])\n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "    return model_inputs\n",
    "\n",
    "def preprocess_dataset_s31(examples):\n",
    "    model_inputs = tokenizer(examples['premise_hypothesis_emotion'])\n",
    "    labels = tokenizer(examples['label_explanation'])\n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "    return model_inputs\n",
    "\n",
    "def preprocess_dataset_s32(examples):\n",
    "    model_inputs = tokenizer(examples['premise_hypothesis_motivation'])\n",
    "    labels = tokenizer(examples['label_explanation'])\n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "    return model_inputs\n",
    "\n",
    "def preprocess_dataset_s33(examples):\n",
    "    model_inputs = tokenizer(examples['premise_hypothesis_consequence'])\n",
    "    labels = tokenizer(examples['label_explanation'])\n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "    return model_inputs\n",
    "\n",
    "def preprocess_dataset_s34(examples):\n",
    "    model_inputs = tokenizer(examples['premise_hypothesis_rot'])\n",
    "    labels = tokenizer(examples['label_explanation'])\n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "    return model_inputs\n",
    "\n",
    "def preprocess_dataset_s35(examples):\n",
    "    model_inputs = tokenizer(examples['premise_hypothesis_all_dims'])\n",
    "    labels = tokenizer(examples['label_explanation'])\n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "    return model_inputs\n",
    "\n",
    "def preprocess_dataset_s41(examples):\n",
    "    model_inputs = tokenizer(examples['premise_hypothesis'])\n",
    "    labels = tokenizer(examples['label'])\n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "    return model_inputs\n",
    "\n",
    "def preprocess_dataset_s42(examples):\n",
    "    model_inputs = tokenizer(examples['premise_hypothesis_label'])\n",
    "    labels = tokenizer(examples['explanation'])\n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "    return model_inputs\n",
    "\n",
    "def preprocess_dataset_s7(examples):\n",
    "    lbl_exp = [ex[ex.find(\"Explanation: \"):] + ex[:ex.find(\"Explanation: \")] for ex in examples['label_explanation']]\n",
    "    model_inputs = tokenizer(examples['premise_hypothesis'])\n",
    "    labels = tokenizer(lbl_exp)\n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "    return model_inputs\n",
    "\n",
    "def get_path(name):\n",
    "    return f\"{name}/{os.listdir(name)[0]}\"\n",
    "\n",
    "def get_prem_hyp(s):\n",
    "    ind = s.find(\"Hypothesis: \")\n",
    "    prem = s[len(\"Premise: \"):ind]\n",
    "    hyp = s[ind + len(\"Hypothesis: \"):]\n",
    "    return [prem, hyp]\n",
    "\n",
    "'''Class encapsulating the two steps of System 4 (Classify, then Explain)'''\n",
    "class DREAM_FLUTE_System4 :\n",
    "    def __init__(self, tokenizer = None, model_s41_path = None, model_s42_path = None) -> None:\n",
    "        self.tokenizer = tokenizer if tokenizer is not None else AutoTokenizer.from_pretrained(\"t5-small\")\n",
    "        self.model_s41 = AutoModelForSeq2SeqLM.from_pretrained(model_s41_path) if model_s41_path is not None else AutoModelForSeq2SeqLM.from_pretrained(\"YoanBOUTE/DREAM-FLUTE-S4-Classify\")\n",
    "        self.model_s42 = AutoModelForSeq2SeqLM.from_pretrained(model_s42_path) if model_s42_path is not None else AutoModelForSeq2SeqLM.from_pretrained(\"YoanBOUTE/DREAM-FLUTE-S4-Explain\")\n",
    "\n",
    "    '''Expected input for function : \"Premise: ... . Hypothesis: ... . Is there a contradiction or entailment between the premise and hypothesis ?\" \n",
    "    Or list of strings in this format'''\n",
    "    def prediction_pipeline(self, inputs) :\n",
    "        if isinstance(inputs, str) :\n",
    "            tok_input = self.tokenizer(inputs, return_tensors='pt').input_ids\n",
    "            output_model_1 = self.model_s41.generate(tok_input, max_new_tokens=100)\n",
    "            decoded_output_model_1 = \"Label: \" + self.tokenizer.decode(output_model_1[0], skip_special_tokens=True)\n",
    "            intermediate_input = inputs[:inputs.find(\"Is there a contradiction or entailment between the premise and hypothesis ?\")] + decoded_output_model_1 + \". What is the explanation of the label associated to the premise and the hypothesis ?\"\n",
    "            tok_intermediate_input = self.tokenizer(intermediate_input, return_tensors='pt').input_ids\n",
    "            output_model_2 = self.model_s42.generate(tok_intermediate_input, max_new_tokens=100)\n",
    "\n",
    "            return decoded_output_model_1 + \". Explanation: \" + self.tokenizer.decode(output_model_2[0], skip_special_tokens=True)\n",
    "        \n",
    "        elif isinstance(inputs, list) and all(isinstance(input, str) for input in inputs) :\n",
    "            predictions = []\n",
    "            for input in inputs :\n",
    "                predictions.append(self.prediction_pipeline(input))\n",
    "            \n",
    "            return predictions\n",
    "        \n",
    "        else :\n",
    "            raise TypeError('Inputs should be either a list of two strings or a list of lists of two strings')\n",
    "        \n",
    "\n",
    "'''Ensemble class that loads all models from HuggingFace (or from the device if a path to the model is indicated) \n",
    "and implements the ensembling algorithm given in the DREAM-FLUTE paper'''\n",
    "class DREAM_FLUTE_Ensemble :\n",
    "    def __init__(self, tokenizer_path = None, s1_path = None, s2_path = None,\n",
    "                 s3_emo_path = None, s3_mot_path = None, s3_cons_path = None,\n",
    "                 s3_rot_path = None, s3_alldims_path = None, s4_clas_path = None, \n",
    "                 s4_exp_path = None, dream_path = None) -> None:\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_path) if tokenizer_path is not None else AutoTokenizer.from_pretrained(\"t5-small\")\n",
    "        self.model_s1 = AutoModelForSeq2SeqLM.from_pretrained(s1_path) if s1_path is not None else AutoModelForSeq2SeqLM.from_pretrained(\"YoanBOUTE/DREAM-FLUTE-S1\")\n",
    "        self.model_s2 = AutoModelForSeq2SeqLM.from_pretrained(s2_path) if s2_path is not None else AutoModelForSeq2SeqLM.from_pretrained(\"YoanBOUTE/DREAM-FLUTE-S2\")\n",
    "        self.model_s3_emo = AutoModelForSeq2SeqLM.from_pretrained(s3_emo_path) if s3_emo_path is not None else AutoModelForSeq2SeqLM.from_pretrained(\"YoanBOUTE/DREAM-FLUTE-S3-Emotion\")\n",
    "        self.model_s3_mot = AutoModelForSeq2SeqLM.from_pretrained(s3_mot_path) if s3_mot_path is not None else AutoModelForSeq2SeqLM.from_pretrained(\"YoanBOUTE/DREAM-FLUTE-S3-Motivation\")\n",
    "        self.model_s3_cons = AutoModelForSeq2SeqLM.from_pretrained(s3_cons_path) if s3_cons_path is not None else AutoModelForSeq2SeqLM.from_pretrained(\"YoanBOUTE/DREAM-FLUTE-S3-Consequence\")\n",
    "        self.model_s3_rot = AutoModelForSeq2SeqLM.from_pretrained(s3_rot_path) if s3_rot_path is not None else AutoModelForSeq2SeqLM.from_pretrained(\"YoanBOUTE/DREAM-FLUTE-S3-ROT\")\n",
    "        self.model_s3_alldims = AutoModelForSeq2SeqLM.from_pretrained(s3_alldims_path) if s3_alldims_path is not None else AutoModelForSeq2SeqLM.from_pretrained(\"YoanBOUTE/DREAM-FLUTE-S3-AllDims\")\n",
    "        self.model_s4 = DREAM_FLUTE_System4(self.tokenizer, s4_clas_path, s4_exp_path)\n",
    "        self.model_dream = AutoModelForSeq2SeqLM.from_pretrained(dream_path) if dream_path is not None else AutoModelForSeq2SeqLM.from_pretrained(\"RicoBorra/DREAM-t5-small\")\n",
    "    \n",
    "    '''Tokenizes the input, then feeds it to the given model, and decodes the output to have a string as result.\n",
    "    This method is callable for all models except System 4 (Use the method defined in the class of System 4)'''\n",
    "    def _prediction_pipeline(self, input : str, model) -> str :\n",
    "        tokenized_input = self.tokenizer(input, return_tensors='pt').input_ids\n",
    "        model_output = model.generate(tokenized_input, max_new_tokens=100)\n",
    "        decoded_output = self.tokenizer.decode(model_output[0], skip_special_tokens=True)\n",
    "        return decoded_output\n",
    "    \n",
    "    '''Preprocesses the input for each model, then feeds it to the pipeline.\n",
    "    Returns a dictionary of all models' predictions.'''\n",
    "    def _get_all_predictions(self, input : list) :\n",
    "        prem, hyp = input \n",
    "        prem = prem.strip()\n",
    "        hyp = hyp.strip()\n",
    "        if not prem.endswith('.') :\n",
    "            prem += '.'\n",
    "        if not hyp.endswith('.') :\n",
    "            hyp += '.' \n",
    "\n",
    "        predictions = dict()\n",
    "\n",
    "        input_1 = f\"Premise: {prem} Hypothesis: {hyp} Is there a contradiction or entailment between the premise and hypothesis ?\"\n",
    "        predictions['S1'] = self._prediction_pipeline(input_1, self.model_s1)\n",
    "\n",
    "        input_2 = f\"Premise: {prem} Hypothesis: {hyp} What is the type of figurative language involved? Is there a contradiction or entailment between the premise and hypothesis ?\"\n",
    "        predictions['S2'] = self._prediction_pipeline(input_2, self.model_s2)\n",
    "\n",
    "        # DREAM elaborations for system 3\n",
    "        input_dream_prem = f\"[SITUATION] {prem} [QUERY] \"\n",
    "        input_dream_hyp = f\"[SITUATION] {hyp} [QUERY] \"\n",
    "        prem_elaborations = {key : self._prediction_pipeline(input_dream_prem + key, self.model_dream) for key in ['emotion', 'motivation', 'consequence', 'rot']}\n",
    "        for key, elab in prem_elaborations.items() :\n",
    "            elab = elab.strip()\n",
    "            if not elab.endswith('.') :\n",
    "                prem_elaborations[key] += '.' \n",
    "        hyp_elaborations = {key : self._prediction_pipeline(input_dream_hyp + key, self.model_dream) for key in ['emotion', 'motivation', 'consequence', 'rot']}\n",
    "        for key, elab in hyp_elaborations.items() :\n",
    "            elab = elab.strip()\n",
    "            if not elab.endswith('.') :\n",
    "                hyp_elaborations[key] += '.' \n",
    "\n",
    "        input_3_emo = f\"Premise: {prem} [Emotion] {prem_elaborations['emotion']} Hypothesis: {hyp} [Emotion] {hyp_elaborations['emotion']} Is there a contradiction or entailment between the premise and hypothesis ?\"\n",
    "        predictions['S3-emo'] = self._prediction_pipeline(input_3_emo, self.model_s3_emo)\n",
    "\n",
    "        input_3_mot = f\"Premise: {prem} [Motivation] {prem_elaborations['motivation']} Hypothesis: {hyp} [Motivation] {hyp_elaborations['motivation']} Is there a contradiction or entailment between the premise and hypothesis ?\"\n",
    "        predictions['S3-mot'] = self._prediction_pipeline(input_3_mot, self.model_s3_mot)\n",
    "\n",
    "        input_3_cons = f\"Premise: {prem} [Consequence] {prem_elaborations['consequence']} Hypothesis: {hyp} [Consequence] {hyp_elaborations['consequence']} Is there a contradiction or entailment between the premise and hypothesis ?\"\n",
    "        predictions['S3-cons'] = self._prediction_pipeline(input_3_cons, self.model_s3_cons)\n",
    "\n",
    "        input_3_rot = f\"Premise: {prem} [Rot] {prem_elaborations['rot']} Hypothesis: {hyp} [Rot] {hyp_elaborations['rot']} Is there a contradiction or entailment between the premise and hypothesis ?\"\n",
    "        predictions['S3-rot'] = self._prediction_pipeline(input_3_rot, self.model_s3_rot)\n",
    "\n",
    "        input_3_all = f\"Premise: {prem} \"\n",
    "        for key, elab in prem_elaborations.items() :\n",
    "            input_3_all += f\"[{key.capitalize()}] {elab} \"\n",
    "        input_3_all += f\"Hypothesis: {hyp} \"\n",
    "        for key, elab in hyp_elaborations.items() :\n",
    "            input_3_all += f\"[{key.capitalize()}] {elab} \"\n",
    "        input_3_all += \"Is there a contradiction or entailment between the premise and hypothesis ?\"\n",
    "        predictions['S3-all'] = self._prediction_pipeline(input_3_all, self.model_s3_alldims)\n",
    "\n",
    "        # The input for system 4 is in the same format as for system 1\n",
    "        predictions['S4'] = self.model_s4.prediction_pipeline(input_1)\n",
    "\n",
    "        return predictions\n",
    "    \n",
    "    '''Uses the predictions from each model to compute the final prediction of the ensemble'''\n",
    "    def _ensemble_algorithm(self, model_outputs) :\n",
    "        # Firstly, the label is selected based on the majority between the 5 best models (according to the paper : systems 1, 2, 3-motivation, 3-alldims, 4)\n",
    "        labels = [model_outputs[key].split('.')[0] for key in ['S1', 'S2', 'S3-mot', 'S3-all', 'S4']]\n",
    "        # Sometimes, it might happen with the small models that the generated label is a mix of words, like 'Contratailment' or 'Endiction'\n",
    "        for label in labels :\n",
    "            if label not in ['Label: Contradiction', 'Label: Entailment'] :\n",
    "                labels.remove(label)\n",
    "        unique, counts = np.unique(labels, return_counts=True)\n",
    "        ix = np.argmax(counts)\n",
    "        major_label = unique[ix]\n",
    "\n",
    "        # Then, pick the explanation of the first system agreeing with the majority label, following an order indicated in the paper\n",
    "        for key in ['S3-cons', 'S3-emo', 'S2', 'S3-all', 'S3-mot', 'S4', 'S1'] :\n",
    "            substrings = model_outputs[key].split('.')\n",
    "            label = substrings[0]\n",
    "            explanation = substrings[1]\n",
    "\n",
    "            if label == major_label :\n",
    "                break\n",
    "\n",
    "        return major_label + '.' + explanation + '.'\n",
    "\n",
    "    '''Expected input : [Premise_sentence, hypothesis_sentence] or list of inputs'''\n",
    "    def predict(self, inputs) :\n",
    "        if isinstance(inputs, list) and all(isinstance(input, str) for input in inputs) and len(inputs) == 2 :\n",
    "            preds = self._get_all_predictions(inputs)\n",
    "            final_pred = self._ensemble_algorithm(preds)\n",
    "        \n",
    "            return final_pred \n",
    "        \n",
    "        elif isinstance(inputs, list) and all(isinstance(input, list) for input in inputs) :\n",
    "            predictions = []\n",
    "            for input in inputs :\n",
    "                predictions.append(self.predict(input))\n",
    "            \n",
    "            return predictions\n",
    "        else :\n",
    "            raise TypeError('Inputs should be either a list of two strings or a list of lists of two strings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "operating_modes = [\n",
    "    (\"system_1\", preprocess_dataset_s1),\n",
    "    (\"system_2\", preprocess_dataset_s2),\n",
    "    (\"system_31\", preprocess_dataset_s31),\n",
    "    (\"system_32\", preprocess_dataset_s32),\n",
    "    (\"system_33\", preprocess_dataset_s33),\n",
    "    (\"system_34\", preprocess_dataset_s34),\n",
    "    (\"system_35\", preprocess_dataset_s35),\n",
    "    (\"system_4\", preprocess_dataset_s1),\n",
    "    (\"system_5\", preprocess_dataset_s1),\n",
    "    (\"system_6\", preprocess_dataset_s1),\n",
    "    (\"system_7\", preprocess_dataset_s7),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(name, model, curr_ds):\n",
    "    training_args = Seq2SeqTrainingArguments(\n",
    "        output_dir=f\"{name}\",\n",
    "        learning_rate=3e-4,\n",
    "        per_device_train_batch_size=BATCH_SIZE,\n",
    "        per_device_eval_batch_size=2*BATCH_SIZE,\n",
    "        save_total_limit=1,\n",
    "        num_train_epochs=NUM_EPOCHS,\n",
    "        report_to=\"none\",\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        eval_accumulation_steps=1,\n",
    "        logging_steps=1,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=curr_ds[\"train\"],\n",
    "        eval_dataset=curr_ds[\"val\"].select(range(350)),\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer),\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'system_1': [0.5960144014132844], 'system_2': [0.6013509440969985], 'system_31': [], 'system_32': [], 'system_33': [], 'system_34': [], 'system_35': [], 'system_4': [], 'system_5': [], 'system_6': [], 'system_7': []}\n",
      "system_2 Label: Entailment. Explanation: It  fun of someone someonea friend is often  and often be very frustratingful and especially if it is to front of stranger that are nots Label: Entailment. Explanation: Being made fun of by a friend is often embarrassing and can be very hurtful, especially if it happens in front of people who are strangers\n",
      "tensor([ 6632,    10,  9422, 13212,     9, 27111,     5, 16229,    10,   695,\n",
      "         5756,   297,     5,  1881,  3767,   257,    10,    94,     3,   694,\n",
      "           13,   841,   841,     9,  1565,    19,   557,     3,    11,   557,\n",
      "           36,   182, 16591,  1329,    11,   902,     3,    99,    34,    19,\n",
      "           12,   851,    13, 13037,    24,    33,    59,     7,     1,     1,\n",
      "            1,     1]) [ 6632    10  9470 13212     9 27111     5 16229    10   695  5756   297\n",
      "     5  1881  3767   257    10  5301   263   694    13    57     3     9\n",
      "  1565    19   557 27445    11    54    36   182  4781  1329     6   902\n",
      "     3    99    34  2906    16   851    13   151   113    33 13037     7\n",
      "     1     0     0     0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bc3b22085804657939ef3d6db77a906",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6780 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73c19520799f40ec99cf9aaf1a4c7e23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/754 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='55' max='565' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 55/565 00:04 < 00:46, 10.86 it/s, Epoch 0.10/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_891/2486041065.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForSeq2SeqLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurr_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# have to do batched rouge computation otherwise not enough memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_891/2472545421.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(name, model, curr_ds)\u001b[0m\n\u001b[1;32m     23\u001b[0m     )\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1535\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1536\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1537\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1538\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1820\u001b[0m             \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1821\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1822\u001b[0m                 \u001b[0mtotal_batched_samples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/accelerate/data_loader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    459\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m                     \u001b[0mcurrent_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msend_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m                 \u001b[0mnext_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip_batches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mcurrent_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__getitems__\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m__getitems__\u001b[0;34m(self, keys)\u001b[0m\n\u001b[1;32m   2797\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2798\u001b[0m         \u001b[0;34m\"\"\"Can be used to get a batch using a list of integers indices.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2799\u001b[0;31m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2800\u001b[0m         \u001b[0mn_examples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2801\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_examples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2793\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: F811\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2794\u001b[0m         \u001b[0;34m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2795\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2797\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m_getitem\u001b[0;34m(self, key, **kwargs)\u001b[0m\n\u001b[1;32m   2778\u001b[0m         \u001b[0mformatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mformat_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2779\u001b[0m         \u001b[0mpa_subtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_indices\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_indices\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2780\u001b[0;31m         formatted_output = format_table(\n\u001b[0m\u001b[1;32m   2781\u001b[0m             \u001b[0mpa_subtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformatter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_all_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_all_columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2782\u001b[0m         )\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/formatting/formatting.py\u001b[0m in \u001b[0;36mformat_table\u001b[0;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[1;32m    627\u001b[0m     \u001b[0mpython_formatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPythonFormatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformat_columns\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mquery_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"column\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformat_columns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/formatting/formatting.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pa_table, query_type)\u001b[0m\n\u001b[1;32m    398\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mquery_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"batch\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mformat_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mRowFormat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/formatting/formatting.py\u001b[0m in \u001b[0;36mformat_batch\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mLazyBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_arrow_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_features_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/formatting/formatting.py\u001b[0m in \u001b[0;36mextract_batch\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextract_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pydict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "modes = {name: [] for name, _ in operating_modes}\n",
    "\n",
    "for train_idxs, val_idxs in indexes[0:4]:\n",
    "    fold_dataset = DatasetDict({\n",
    "        \"train\": ds.select(train_idxs),\n",
    "        \"val\": ds.select(val_idxs)\n",
    "    })\n",
    "\n",
    "    for name, preprocess_func in operating_modes:\n",
    "        curr_ds = fold_dataset.map(preprocess_func, batched=True).remove_columns(fold_dataset['train'].column_names)\n",
    "\n",
    "        if name == \"system_4\":\n",
    "            ds_41 = fold_dataset.map(preprocess_dataset_s41, batched=True).remove_columns(fold_dataset['train'].column_names)\n",
    "            train_model(\"system_41\", AutoModelForSeq2SeqLM.from_pretrained(base_checkpoint), ds_41)\n",
    "            ds_42 = fold_dataset.map(preprocess_dataset_s42, batched=True).remove_columns(fold_dataset['train'].column_names)\n",
    "            train_model(\"system_42\", AutoModelForSeq2SeqLM.from_pretrained(base_checkpoint), ds_42)\n",
    "        elif name == \"system_5\":\n",
    "            pass\n",
    "        else:\n",
    "            if name == \"system_6\":\n",
    "                model = AutoModelForSeq2SeqLM.from_pretrained(\"RicoBorra/T5-small-synthetic-FLUTE\")\n",
    "            else:\n",
    "                model = AutoModelForSeq2SeqLM.from_pretrained(base_checkpoint)\n",
    "            trainer = train_model(name, model, curr_ds)\n",
    "            \n",
    "        # have to do batched rouge computation otherwise not enough memory\n",
    "        rouge = evaluate.load(\"rouge\")\n",
    "        metrics = {'rouge1': 0., 'rouge2': 0., 'rougeL': 0., 'rougeLsum': 0.}\n",
    "        count = 0\n",
    "        for i in range(0, len(curr_ds['val']), N_GEN):\n",
    "            count += 1\n",
    "            if (name != \"system_4\") and (name != \"system_5\"):\n",
    "                (predictions, _), label_ids, _ = trainer.predict(test_dataset=curr_ds['val'].select(range(i, min(i+N_GEN, len(curr_ds['val'])))))\n",
    "                # delete stuff after EOS token\n",
    "                predicted_token_ids = torch.argmax(torch.from_numpy(predictions), dim=-1)\n",
    "                for j in range(predicted_token_ids.shape[0]):\n",
    "                    ind = (predicted_token_ids[j] == 1).nonzero(as_tuple=True)[0]\n",
    "                    if ind.numel() != 0:\n",
    "                        predicted_token_ids[j, ind[0]:] = 1\n",
    "                decoded_preds = tokenizer.batch_decode(predicted_token_ids, skip_special_tokens=True)\n",
    "                # clean decoded preds if needed\n",
    "                if name == \"system_2\":\n",
    "                    decoded_preds = [dp[dp.find(\"Label\"):] for dp in decoded_preds]\n",
    "                if name == \"system_7\":\n",
    "                    decoded_preds = [ex[ex.find(\"Label: \"):] + \" \" + ex[:ex.find(\"Label: \")] for ex in decoded_preds]\n",
    "\n",
    "            else:\n",
    "                small_ds = curr_ds['val'].select(range(i, min(i+N_GEN, len(curr_ds['val']))))\n",
    "                label_ids = small_ds['labels']\n",
    "                inputs = tokenizer.batch_decode(small_ds['input_ids'], skip_special_tokens=True)\n",
    "                if name == \"system_4\":\n",
    "                    sys_4 = DREAM_FLUTE_System4(tokenizer=None, model_s41_path=get_path(\"system_41\"), model_s42_path=get_path(\"system_42\"))\n",
    "                    decoded_preds = sys_4.prediction_pipeline(inputs=inputs)\n",
    "                else: # \"name == system_5\"\n",
    "                    inputs = [get_prem_hyp(ex) for ex in inputs]\n",
    "                    sys_5 = DREAM_FLUTE_Ensemble(\n",
    "                        tokenizer_path=None, \n",
    "                        s1_path=get_path(\"system_1\"),\n",
    "                        s2_path=get_path(\"system_2\"),\n",
    "                        s3_emo_path=get_path(\"system_31\"),\n",
    "                        s3_mot_path=get_path(\"system_32\"),\n",
    "                        s3_cons_path=get_path(\"system_33\"),\n",
    "                        s3_rot_path=get_path(\"system_34\"),\n",
    "                        s3_alldims_path=get_path(\"system_35\"),\n",
    "                        s4_clas_path=get_path(\"system_41\"),\n",
    "                        s4_exp_path=get_path(\"system_42\"),\n",
    "                        dream_path=None)\n",
    "                    decoded_preds = sys_5.predict(inputs=inputs)\n",
    "                \n",
    "            # careful here\n",
    "            labels = np.where(label_ids != -100, label_ids, tokenizer.pad_token_id)\n",
    "            decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "            if name == \"system_2\":\n",
    "                decoded_labels = [dp[dp.find(\"Label\"):] for dp in decoded_labels]\n",
    "            if name == \"system_7\":\n",
    "                decoded_labels = [ex[ex.find(\"Label: \"):] + \" \" + ex[:ex.find(\"Label: \")] for ex in decoded_labels]\n",
    "\n",
    "            new_metrics = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "            for k in new_metrics:\n",
    "                metrics[k] += new_metrics[k]\n",
    "\n",
    "        for k in metrics:\n",
    "                metrics[k] /= count\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        modes[name].append(metrics['rouge1'])\n",
    "        print(modes)\n",
    "        #print(name, decoded_preds[0], decoded_labels[0])\n",
    "        records.append({'name': name, \"content\": decoded_preds[0]})\n",
    "        #print(predicted_token_ids[0], labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records.append({'name': \"ground_truth\", 'content': decoded_labels[0]})\n",
    "records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n{'system_1': [0.5056115530372459, 0.5085812472965738], 'system_2': [0.5323239453833644, 0.5374525863206762], 'system_31': [0.5084813364883226, 0.5078069259932709], 'system_32': [0.5055255195638098, 0.5074808302929493], 'system_33': [0.5032615710245999, 0.508591734512484], 'system_34': [0.5067396302748032, 0.5087587260751042], 'system_35': [0.5036829298423671, 0.5073656197676405]}\\n{'system_1': [0.47329270980754923], 'system_2': [0.5039333868999851], 'system_31': [0.47420432731446144], 'system_32': [0.473849787491779], 'system_33': [0.47287909150934293], 'system_34': [0.47171914165316353], 'system_35': [0.47436950304876985]}\\n{'system_1': [0.5221458462682274, 0.4906728974226775], 'system_2': [0.5453307495230577, 0.5189864534869755], 'system_31': [0.524029905213074, 0.49432447432649923], 'system_32': [0.5236538569098267, 0.4949640794043393], 'system_33': [0.522696825432352, 0.49418902866839187], 'system_34': [0.5231002650281118, 0.49245360907178504], 'system_35': [0.5238553839735753, 0.4967562420314123]}\\n{'system_1': [0.5201383622010409, 0.5019083214066056], 'system_2': [0.5451744732719431, 0.5273190341222926], 'system_31': [0.5192974336052382, 0.5002995114825706], 'system_32': [0.5188841013023715, 0.5007719063422055], 'system_33': [0.5203219622545853, 0.49992736417041994], 'system_34': [0.5180675680247785, 0.5008015168679895], 'system_35': [0.5224425242712794, 0.5010754435268072]}\\n{'system_1': [0.49590791112913984], 'system_2': [0.5147096144113823], 'system_31': [0.4927430972029428], 'system_32': [0.49258799343269694], 'system_33': [0.49049952341283654], 'system_34': [0.49317378483047924], 'system_35': [0.4919880906784929]}\\n\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "{'system_1': [0.5056115530372459, 0.5085812472965738], 'system_2': [0.5323239453833644, 0.5374525863206762], 'system_31': [0.5084813364883226, 0.5078069259932709], 'system_32': [0.5055255195638098, 0.5074808302929493], 'system_33': [0.5032615710245999, 0.508591734512484], 'system_34': [0.5067396302748032, 0.5087587260751042], 'system_35': [0.5036829298423671, 0.5073656197676405]}\n",
    "{'system_1': [0.47329270980754923], 'system_2': [0.5039333868999851], 'system_31': [0.47420432731446144], 'system_32': [0.473849787491779], 'system_33': [0.47287909150934293], 'system_34': [0.47171914165316353], 'system_35': [0.47436950304876985]}\n",
    "{'system_1': [0.5221458462682274, 0.4906728974226775], 'system_2': [0.5453307495230577, 0.5189864534869755], 'system_31': [0.524029905213074, 0.49432447432649923], 'system_32': [0.5236538569098267, 0.4949640794043393], 'system_33': [0.522696825432352, 0.49418902866839187], 'system_34': [0.5231002650281118, 0.49245360907178504], 'system_35': [0.5238553839735753, 0.4967562420314123]}\n",
    "{'system_1': [0.5201383622010409, 0.5019083214066056], 'system_2': [0.5451744732719431, 0.5273190341222926], 'system_31': [0.5192974336052382, 0.5002995114825706], 'system_32': [0.5188841013023715, 0.5007719063422055], 'system_33': [0.5203219622545853, 0.49992736417041994], 'system_34': [0.5180675680247785, 0.5008015168679895], 'system_35': [0.5224425242712794, 0.5010754435268072]}\n",
    "{'system_1': [0.49590791112913984], 'system_2': [0.5147096144113823], 'system_31': [0.4927430972029428], 'system_32': [0.49258799343269694], 'system_33': [0.49049952341283654], 'system_34': [0.49317378483047924], 'system_35': [0.4919880906784929]}\n",
    "{'system_1': [0.498351050356349, 0.5090844074007058], 'system_2': [0.5289706096196247, 0.535423121872322], 'system_31': [0.5004418699772601, 0.5081924349139884], 'system_32': [0.5000023839289528, 0.5069172466751917], 'system_33': [0.49609349538092806, 0.5060478473679386], 'system_34': [0.49683869684920356, 0.5072891134960673], 'system_35': [0.49873229852851614, 0.5063988604083957]}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Premise: I hope that, as neighbours, we may live long in peace and amity, and in the rare exchange of any sort of assistance which should subsist between us. Hypothesis: I hope that, as neighbours, we may live long in peace and amity, and in the interchange of those good offices which should subsist between us. Is there a contradiction or entailment between the premise and hypothesis?'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'system_1': [0.498351050356349, 0.5090844074007058],\n",
       " 'system_2': [0.5289706096196247, 0.535423121872322],\n",
       " 'system_31': [0.5004418699772601, 0.5081924349139884],\n",
       " 'system_32': [0.5000023839289528, 0.5069172466751917],\n",
       " 'system_33': [0.49609349538092806, 0.5060478473679386],\n",
       " 'system_34': [0.49683869684920356, 0.5072891134960673],\n",
       " 'system_35': [0.49873229852851614, 0.5063988604083957]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [{'system_1': [0.5056115530372459, 0.5085812472965738], 'system_2': [0.5323239453833644, 0.5374525863206762], 'system_31': [0.5084813364883226, 0.5078069259932709], 'system_32': [0.5055255195638098, 0.5074808302929493], 'system_33': [0.5032615710245999, 0.508591734512484], 'system_34': [0.5067396302748032, 0.5087587260751042], 'system_35': [0.5036829298423671, 0.5073656197676405]},\n",
    "{'system_1': [0.47329270980754923], 'system_2': [0.5039333868999851], 'system_31': [0.47420432731446144], 'system_32': [0.473849787491779], 'system_33': [0.47287909150934293], 'system_34': [0.47171914165316353], 'system_35': [0.47436950304876985]},\n",
    "{'system_1': [0.5221458462682274, 0.4906728974226775], 'system_2': [0.5453307495230577, 0.5189864534869755], 'system_31': [0.524029905213074, 0.49432447432649923], 'system_32': [0.5236538569098267, 0.4949640794043393], 'system_33': [0.522696825432352, 0.49418902866839187], 'system_34': [0.5231002650281118, 0.49245360907178504], 'system_35': [0.5238553839735753, 0.4967562420314123]},\n",
    "{'system_1': [0.5201383622010409, 0.5019083214066056], 'system_2': [0.5451744732719431, 0.5273190341222926], 'system_31': [0.5192974336052382, 0.5002995114825706], 'system_32': [0.5188841013023715, 0.5007719063422055], 'system_33': [0.5203219622545853, 0.49992736417041994], 'system_34': [0.5180675680247785, 0.5008015168679895], 'system_35': [0.5224425242712794, 0.5010754435268072]},\n",
    "{'system_1': [0.49590791112913984], 'system_2': [0.5147096144113823], 'system_31': [0.4927430972029428], 'system_32': [0.49258799343269694], 'system_33': [0.49049952341283654], 'system_34': [0.49317378483047924], 'system_35': [0.4919880906784929]},\n",
    "{'system_1': [0.498351050356349, 0.5090844074007058], 'system_2': [0.5289706096196247, 0.535423121872322], 'system_31': [0.5004418699772601, 0.5081924349139884], 'system_32': [0.5000023839289528, 0.5069172466751917], 'system_33': [0.49609349538092806, 0.5060478473679386], 'system_34': [0.49683869684920356, 0.5072891134960673], 'system_35': [0.49873229852851614, 0.5063988604083957]},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "for key in l[0].keys():\n",
    "    d[key] = []\n",
    "    for el in l:\n",
    "        d[key] += el[key]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'system_1': [0.5056115530372459,\n",
       "  0.5085812472965738,\n",
       "  0.47329270980754923,\n",
       "  0.5221458462682274,\n",
       "  0.4906728974226775,\n",
       "  0.5201383622010409,\n",
       "  0.5019083214066056,\n",
       "  0.49590791112913984,\n",
       "  0.498351050356349,\n",
       "  0.5090844074007058],\n",
       " 'system_2': [0.5323239453833644,\n",
       "  0.5374525863206762,\n",
       "  0.5039333868999851,\n",
       "  0.5453307495230577,\n",
       "  0.5189864534869755,\n",
       "  0.5451744732719431,\n",
       "  0.5273190341222926,\n",
       "  0.5147096144113823,\n",
       "  0.5289706096196247,\n",
       "  0.535423121872322],\n",
       " 'system_31': [0.5084813364883226,\n",
       "  0.5078069259932709,\n",
       "  0.47420432731446144,\n",
       "  0.524029905213074,\n",
       "  0.49432447432649923,\n",
       "  0.5192974336052382,\n",
       "  0.5002995114825706,\n",
       "  0.4927430972029428,\n",
       "  0.5004418699772601,\n",
       "  0.5081924349139884],\n",
       " 'system_32': [0.5055255195638098,\n",
       "  0.5074808302929493,\n",
       "  0.473849787491779,\n",
       "  0.5236538569098267,\n",
       "  0.4949640794043393,\n",
       "  0.5188841013023715,\n",
       "  0.5007719063422055,\n",
       "  0.49258799343269694,\n",
       "  0.5000023839289528,\n",
       "  0.5069172466751917],\n",
       " 'system_33': [0.5032615710245999,\n",
       "  0.508591734512484,\n",
       "  0.47287909150934293,\n",
       "  0.522696825432352,\n",
       "  0.49418902866839187,\n",
       "  0.5203219622545853,\n",
       "  0.49992736417041994,\n",
       "  0.49049952341283654,\n",
       "  0.49609349538092806,\n",
       "  0.5060478473679386],\n",
       " 'system_34': [0.5067396302748032,\n",
       "  0.5087587260751042,\n",
       "  0.47171914165316353,\n",
       "  0.5231002650281118,\n",
       "  0.49245360907178504,\n",
       "  0.5180675680247785,\n",
       "  0.5008015168679895,\n",
       "  0.49317378483047924,\n",
       "  0.49683869684920356,\n",
       "  0.5072891134960673],\n",
       " 'system_35': [0.5036829298423671,\n",
       "  0.5073656197676405,\n",
       "  0.47436950304876985,\n",
       "  0.5238553839735753,\n",
       "  0.4967562420314123,\n",
       "  0.5224425242712794,\n",
       "  0.5010754435268072,\n",
       "  0.4919880906784929,\n",
       "  0.49873229852851614,\n",
       "  0.5063988604083957]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system_2 Ttest_relResult(statistic=23.19102411438574, pvalue=1.2259514290288666e-09)\n",
      "system_31 Ttest_relResult(statistic=0.5948201499859518, pvalue=0.2833078171850142)\n",
      "system_32 Ttest_relResult(statistic=-0.15212858962856382, pvalue=0.5587793758146149)\n",
      "system_33 Ttest_relResult(statistic=-1.4525349538900347, pvalue=0.9098456440410234)\n",
      "system_34 Ttest_relResult(statistic=-1.3719083987600567, pvalue=0.898341997218993)\n",
      "system_35 Ttest_relResult(statistic=0.10660074133722681, pvalue=0.45872204141041606)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_rel\n",
    "# paired t test\n",
    "for key in list(l[0].keys())[1:]:\n",
    "    print(key, ttest_rel(d[key], d[\"system_1\"], alternative=\"greater\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
