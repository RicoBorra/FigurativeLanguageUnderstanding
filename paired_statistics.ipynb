{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from datasets import Dataset, DatasetDict, load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Trainer\n",
    "import pandas as pd\n",
    "import torch\n",
    "import evaluate\n",
    "import nltk\n",
    "\n",
    "BATCH_SIZE = 12\n",
    "NUM_EPOCHS = 8\n",
    "base_checkpoint = \"t5-small\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_checkpoint)\n",
    "\n",
    "#ds = load_dataset(\"ColumbiaNLP/FLUTE\").shuffle(seed=42)\n",
    "df = pd.read_csv(\"complete_dataset.csv\").fillna(\"\")\n",
    "ds = Dataset.from_pandas(df).shuffle(seed=42)\n",
    "folds = StratifiedKFold(n_splits=10, shuffle=False)\n",
    "splits = folds.split(ds, ds['label'])\n",
    "indexes = [t for t in splits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f45a78cad5944534ad73da039d4ee1f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7534 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from flute_dream import add_combined_cols\n",
    "\n",
    "ds = ds.map(add_combined_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset_s1(examples):\n",
    "    model_inputs = tokenizer(examples['premise_hypothesis'])\n",
    "    labels = tokenizer(examples['label_explanation'])\n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "    return model_inputs\n",
    "\n",
    "def preprocess_dataset_s2(examples):\n",
    "    model_inputs = tokenizer(examples['premise_hypothesis_system_2'])\n",
    "    labels = tokenizer(examples['type_label_explanation'])\n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "    return model_inputs\n",
    "\n",
    "def preprocess_dataset_s31(examples):\n",
    "    model_inputs = tokenizer(examples['premise_hypothesis_emotion'])\n",
    "    labels = tokenizer(examples['label_explanation'])\n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "    return model_inputs\n",
    "\n",
    "def preprocess_dataset_s32(examples):\n",
    "    model_inputs = tokenizer(examples['premise_hypothesis_motivation'])\n",
    "    labels = tokenizer(examples['label_explanation'])\n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "    return model_inputs\n",
    "\n",
    "def preprocess_dataset_s33(examples):\n",
    "    model_inputs = tokenizer(examples['premise_hypothesis_consequence'])\n",
    "    labels = tokenizer(examples['label_explanation'])\n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "    return model_inputs\n",
    "\n",
    "def preprocess_dataset_s34(examples):\n",
    "    model_inputs = tokenizer(examples['premise_hypothesis_rot'])\n",
    "    labels = tokenizer(examples['label_explanation'])\n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "    return model_inputs\n",
    "\n",
    "def preprocess_dataset_s35(examples):\n",
    "    model_inputs = tokenizer(examples['premise_hypothesis_all_dims'])\n",
    "    labels = tokenizer(examples['label_explanation'])\n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "    return model_inputs\n",
    "\n",
    "def preprocess_dataset_s41(examples):\n",
    "    model_inputs = tokenizer(examples['premise_hypothesis'])\n",
    "    labels = tokenizer(examples['label'])\n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "    return model_inputs\n",
    "\n",
    "def preprocess_dataset_s42(examples):\n",
    "    model_inputs = tokenizer(examples['premise_hypothesis_label'])\n",
    "    labels = tokenizer(examples['explanation'])\n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "operating_modes = [\n",
    "    (\"system_1\", preprocess_dataset_s1),\n",
    "    (\"system_2\", preprocess_dataset_s2),\n",
    "    (\"system_31\", preprocess_dataset_s31),\n",
    "    (\"system_32\", preprocess_dataset_s32),\n",
    "    (\"system_33\", preprocess_dataset_s33),\n",
    "    (\"system_34\", preprocess_dataset_s34),\n",
    "    (\"system_35\", preprocess_dataset_s35),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'system_1': [0.47329270980754923], 'system_2': [0.5039333868999851], 'system_31': [0.47420432731446144], 'system_32': [0.473849787491779], 'system_33': [0.47287909150934293], 'system_34': [0.47171914165316353], 'system_35': []}\n",
      "{'system_1': [0.47329270980754923], 'system_2': [0.5039333868999851], 'system_31': [0.47420432731446144], 'system_32': [0.473849787491779], 'system_33': [0.47287909150934293], 'system_34': [0.47171914165316353], 'system_35': [0.47436950304876985]}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbb95e9638d54c6aa67b3b5b86f33334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6780 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fce48e17b5b9424188420a8f55699900",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/754 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1847' max='4520' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1847/4520 02:32 < 03:40, 12.11 it/s, Epoch 3.27/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.717700</td>\n",
       "      <td>1.512547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.351300</td>\n",
       "      <td>1.415790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.760400</td>\n",
       "      <td>1.360979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31074/1936148469.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m         )\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# have to do batched rouge computation otherwise not enough memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1535\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1536\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1537\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1538\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1857\u001b[0m                     \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging_nan_inf_filter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1858\u001b[0m                     \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_torch_tpu_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1859\u001b[0;31m                     \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1860\u001b[0m                 ):\n\u001b[1;32m   1861\u001b[0m                     \u001b[0;31m# if loss is nan or inf simply add the average of previous logged losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "modes = {name: [] for name, _ in operating_modes}\n",
    "\n",
    "for train_idxs, val_idxs in indexes[3:]:\n",
    "    fold_dataset = DatasetDict({\n",
    "        \"train\": ds.select(train_idxs),\n",
    "        \"val\": ds.select(val_idxs)\n",
    "    })\n",
    "\n",
    "    for name, preprocess_func in operating_modes:\n",
    "        curr_ds = fold_dataset.map(preprocess_func, batched=True).remove_columns(fold_dataset['train'].column_names)\n",
    "\n",
    "        training_args = Seq2SeqTrainingArguments(\n",
    "            output_dir=f\"{name}\",\n",
    "            learning_rate=3e-4,\n",
    "            per_device_train_batch_size=BATCH_SIZE,\n",
    "            per_device_eval_batch_size=2*BATCH_SIZE,\n",
    "            save_total_limit=2,\n",
    "            num_train_epochs=NUM_EPOCHS,\n",
    "            report_to=\"none\",\n",
    "            evaluation_strategy=\"epoch\",\n",
    "            save_strategy=\"epoch\",\n",
    "            eval_accumulation_steps=1,\n",
    "            logging_steps=1,\n",
    "        )\n",
    "\n",
    "        model = AutoModelForSeq2SeqLM.from_pretrained(base_checkpoint)\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=curr_ds[\"train\"],\n",
    "            eval_dataset=curr_ds[\"val\"].select(range(350)),\n",
    "            tokenizer=tokenizer,\n",
    "            data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer),\n",
    "        )\n",
    "\n",
    "        trainer.train()\n",
    "        \n",
    "        # have to do batched rouge computation otherwise not enough memory\n",
    "        rouge = evaluate.load(\"rouge\")\n",
    "        metrics = {'rouge1': 0., 'rouge2': 0., 'rougeL': 0., 'rougeLsum': 0.}\n",
    "        count = 0\n",
    "        for i in range(0, len(curr_ds['val']), 100):\n",
    "            count += 1\n",
    "            (predictions, _), label_ids, _ = trainer.predict(test_dataset=curr_ds['val'].select(range(i, min(i+100, len(curr_ds['val'])))))\n",
    "            predicted_token_ids = torch.argmax(torch.from_numpy(predictions), dim=-1)\n",
    "            decoded_preds = tokenizer.batch_decode(predicted_token_ids, skip_special_tokens=True)\n",
    "            labels = np.where(label_ids != -100, label_ids, tokenizer.pad_token_id)\n",
    "            decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "            new_metrics = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "            for k in new_metrics:\n",
    "                metrics[k] += new_metrics[k]\n",
    "\n",
    "        for k in metrics:\n",
    "                metrics[k] /= count\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        modes[name].append(metrics['rouge1'])\n",
    "        print(modes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "{'system_1': [0.5056115530372459, 0.5085812472965738], 'system_2': [0.5323239453833644, 0.5374525863206762], 'system_31': [0.5084813364883226, 0.5078069259932709], 'system_32': [0.5055255195638098, 0.5074808302929493], 'system_33': [0.5032615710245999, 0.508591734512484], 'system_34': [0.5067396302748032, 0.5087587260751042], 'system_35': [0.5036829298423671, 0.5073656197676405]}\n",
    "{'system_1': [0.47329270980754923], 'system_2': [0.5039333868999851], 'system_31': [0.47420432731446144], 'system_32': [0.473849787491779], 'system_33': [0.47287909150934293], 'system_34': [0.47171914165316353], 'system_35': [0.47436950304876985]}\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
