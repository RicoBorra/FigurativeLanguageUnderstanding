{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritam/Documents/polito/dnlp/FigurativeLanguageUnderstanding/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "BASE_DIR = Path(\".\")\n",
    "BATCH_SIZE = 8\n",
    "NUM_EPOCHS = 5\n",
    "NUM_SAMPLES = 1_000\n",
    "MULTI_STAGES = False\n",
    "FREEZE = False\n",
    "FROZEN_LAYERS = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"google/t5-efficient-tiny\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 256)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 256)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=256, out_features=256, bias=False)\n",
       "              (k): Linear(in_features=256, out_features=256, bias=False)\n",
       "              (v): Linear(in_features=256, out_features=256, bias=False)\n",
       "              (o): Linear(in_features=256, out_features=256, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 4)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=256, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=256, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-3): 3 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=256, out_features=256, bias=False)\n",
       "              (k): Linear(in_features=256, out_features=256, bias=False)\n",
       "              (v): Linear(in_features=256, out_features=256, bias=False)\n",
       "              (o): Linear(in_features=256, out_features=256, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=256, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=256, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 256)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=256, out_features=256, bias=False)\n",
       "              (k): Linear(in_features=256, out_features=256, bias=False)\n",
       "              (v): Linear(in_features=256, out_features=256, bias=False)\n",
       "              (o): Linear(in_features=256, out_features=256, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 4)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=256, out_features=256, bias=False)\n",
       "              (k): Linear(in_features=256, out_features=256, bias=False)\n",
       "              (v): Linear(in_features=256, out_features=256, bias=False)\n",
       "              (o): Linear(in_features=256, out_features=256, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=256, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=256, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-3): 3 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=256, out_features=256, bias=False)\n",
       "              (k): Linear(in_features=256, out_features=256, bias=False)\n",
       "              (v): Linear(in_features=256, out_features=256, bias=False)\n",
       "              (o): Linear(in_features=256, out_features=256, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=256, out_features=256, bias=False)\n",
       "              (k): Linear(in_features=256, out_features=256, bias=False)\n",
       "              (v): Linear(in_features=256, out_features=256, bias=False)\n",
       "              (o): Linear(in_features=256, out_features=256, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=256, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=256, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=256, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n",
      "2000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pairID</th>\n",
       "      <th>gold_label</th>\n",
       "      <th>Sentence1</th>\n",
       "      <th>Sentence2</th>\n",
       "      <th>Explanation_1</th>\n",
       "      <th>WorkerId</th>\n",
       "      <th>Sentence1_marked_1</th>\n",
       "      <th>Sentence2_marked_1</th>\n",
       "      <th>Sentence1_Highlighted_1</th>\n",
       "      <th>Sentence2_Highlighted_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3416050480.jpg#4r1n</td>\n",
       "      <td>neutral</td>\n",
       "      <td>A person on a horse jumps over a broken down a...</td>\n",
       "      <td>A person is training his horse for a competition.</td>\n",
       "      <td>the person is not necessarily training his horse</td>\n",
       "      <td>AF0PI3RISB5Q7</td>\n",
       "      <td>A person on a horse jumps over a broken down a...</td>\n",
       "      <td>A person is *training* *his* *horse* for a co...</td>\n",
       "      <td>{}</td>\n",
       "      <td>3,4,5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                pairID gold_label  \\\n",
       "0  3416050480.jpg#4r1n    neutral   \n",
       "\n",
       "                                           Sentence1  \\\n",
       "0  A person on a horse jumps over a broken down a...   \n",
       "\n",
       "                                           Sentence2  \\\n",
       "0  A person is training his horse for a competition.   \n",
       "\n",
       "                                      Explanation_1       WorkerId  \\\n",
       "0  the person is not necessarily training his horse  AF0PI3RISB5Q7   \n",
       "\n",
       "                                  Sentence1_marked_1  \\\n",
       "0  A person on a horse jumps over a broken down a...   \n",
       "\n",
       "                                  Sentence2_marked_1 Sentence1_Highlighted_1  \\\n",
       "0   A person is *training* *his* *horse* for a co...                      {}   \n",
       "\n",
       "  Sentence2_Highlighted_1  \n",
       "0                   3,4,5  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_snli_train_1 = pd.read_csv(BASE_DIR / \"datasets\" / \"esnli_train_1.csv\")[:NUM_SAMPLES]\n",
    "e_snli_train_2 = pd.read_csv(BASE_DIR / \"datasets\" / \"esnli_train_2.csv\")[:NUM_SAMPLES]\n",
    "e_snli_train = pd.concat([e_snli_train_1, e_snli_train_2])\n",
    "\n",
    "e_snli_test = pd.read_csv(BASE_DIR / \"datasets\" / \"esnli_test.csv\")[:NUM_SAMPLES]\n",
    "\n",
    "print(len(e_snli_train_1))\n",
    "print(len(e_snli_train_2))\n",
    "print(len(e_snli_train))\n",
    "e_snli_train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Map: 100%|██████████| 500/500 [00:00<00:00, 5172.33 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'labels'],\n",
       "    num_rows: 500\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import (\n",
    "    T5ForConditionalGeneration,\n",
    "    T5Tokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "\n",
    "dataset = Dataset.from_pandas(e_snli_train)\n",
    "\n",
    "model_name = \"t5-small\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "def preprocess_function(batch):\n",
    "    pairIDs = batch[\"pairID\"]\n",
    "    gold_labels = batch[\"gold_label\"]\n",
    "    Sentence1s = batch[\"Sentence1\"]\n",
    "    Sentence2s = batch[\"Sentence2\"]\n",
    "    Explanation_1s = batch[\"Explanation_1\"]\n",
    "    WorkerIds = batch[\"WorkerId\"]\n",
    "    Sentence1_marked_1s = batch[\"Sentence1_marked_1\"]\n",
    "    Sentence2_marked_1s = batch[\"Sentence2_marked_1\"]\n",
    "    Sentence1_Highlighted_1s = batch[\"Sentence1_Highlighted_1\"]\n",
    "    Sentence2_Highlighted_1s = batch[\"Sentence2_Highlighted_1\"]\n",
    "\n",
    "    inputs = [\n",
    "        f\"Does the sentence '{s1}' entail or contradict the sentence '{s2}'? Please answer between 'Entails' or 'Contradicts' and explain your decision in a sentence.\"\n",
    "        for s1, s2 in zip(Sentence1s, Sentence2s)\n",
    "    ]\n",
    "\n",
    "    targets = [\n",
    "        f\"{label} - {explanation}\"\n",
    "        for label, explanation in zip(gold_labels, Explanation_1s)\n",
    "    ]\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        inputs,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=20,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    targets = tokenizer(\n",
    "        targets,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=20,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    return {\"input_ids\": inputs[\"input_ids\"], \"labels\": targets[\"input_ids\"]}\n",
    "\n",
    "\n",
    "# https://huggingface.co/docs/transformers/main_classes/data_collator\n",
    "\n",
    "tokenized_datasets = dataset.select(range(500)).map(preprocess_function, batched=True)\n",
    "tokenized_datasets.remove_columns(\n",
    "    [\n",
    "        \"pairID\",\n",
    "        \"gold_label\",\n",
    "        \"Sentence1\",\n",
    "        \"Sentence2\",\n",
    "        \"Explanation_1\",\n",
    "        \"WorkerId\",\n",
    "        \"Sentence1_marked_1\",\n",
    "        \"Sentence2_marked_1\",\n",
    "        \"Sentence1_Highlighted_1\",\n",
    "        \"Sentence2_Highlighted_1\",\n",
    "        \"__index_level_0__\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"rouge\")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    print(\"Before decoding\")\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    print(decoded_preds)\n",
    "    print(decoded_labels)\n",
    "    result = metric.compute(\n",
    "        predictions=decoded_preds, references=decoded_labels, use_stemmer=True\n",
    "    )\n",
    "    print(\"result\", result)\n",
    "    return result[\"rouge1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"models\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    per_device_eval_batch_size=1,\n",
    "    per_device_train_batch_size=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_dataset = tokenized_datasets.shuffle(seed=42).select(range(500))\n",
    "small_eval_dataset = tokenized_datasets.shuffle(seed=42).select(range(500))\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train_dataset,\n",
    "    eval_dataset=small_eval_dataset,\n",
    "    # compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 13)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_eval_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1500 [00:00<?, ?it/s]You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 500/1500 [00:21<00:41, 24.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.1964, 'learning_rate': 3.3333333333333335e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 34%|███▎      | 505/1500 [00:25<05:11,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.1255650520324707, 'eval_runtime': 2.9202, 'eval_samples_per_second': 171.221, 'eval_steps_per_second': 171.221, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 1000/1500 [00:46<00:20, 24.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.3043, 'learning_rate': 1.6666666666666667e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 67%|██████▋   | 1003/1500 [00:50<03:22,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.9352325201034546, 'eval_runtime': 3.1034, 'eval_samples_per_second': 161.111, 'eval_steps_per_second': 161.111, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [01:11<00:00, 23.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1629, 'learning_rate': 0.0, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "100%|██████████| 1500/1500 [01:14<00:00, 20.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.8929709196090698, 'eval_runtime': 3.0619, 'eval_samples_per_second': 163.296, 'eval_steps_per_second': 163.296, 'epoch': 3.0}\n",
      "{'train_runtime': 74.8938, 'train_samples_per_second': 20.028, 'train_steps_per_second': 20.028, 'train_loss': 2.5545413411458333, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1500, training_loss=2.5545413411458333, metrics={'train_runtime': 74.8938, 'train_samples_per_second': 20.028, 'train_steps_per_second': 20.028, 'train_loss': 2.5545413411458333, 'epoch': 3.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:10<00:00, 46.68it/s] "
     ]
    }
   ],
   "source": [
    "predictions = trainer.predict(small_eval_dataset)\n",
    "\n",
    "decoded_preds = tokenizer.batch_decode(\n",
    "    predictions.predictions, skip_special_tokens=True\n",
    ")\n",
    "\n",
    "print(decoded_preds)\n",
    "\n",
    "# crashes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
