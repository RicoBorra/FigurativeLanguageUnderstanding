{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from random import randint\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "NUM_SAMPLES = 2\n",
    "NUM_ITER = 200  # 200 (num_iter) * 5 (batch_size) * 8 (types) = 8k\n",
    "BATCH_SIZE = 5\n",
    "BASE_DIR = Path(\".\")\n",
    "filename = \"synthetic_data_stages.tsv\"\n",
    "\n",
    "model_name_or_path = \"TheBloke/CapybaraHermes-2.5-Mistral-7B-GPTQ\"\n",
    "revision = \"main\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name_or_path, device_map=\"cuda\", trust_remote_code=False, revision=revision\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=True)\n",
    "if filename not in os.listdir(BASE_DIR):\n",
    "    with open(BASE_DIR / filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"hypothesis\\tpremise\\tlabel\\texplanation\\ttype\" + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sarcasm\n",
    "\n",
    "For sarcasm generation, we use the [empathetic dialogues dataset](https://huggingface.co/datasets/empathetic_dialogues).\n",
    "\n",
    "First, we create a paraphrase. Then, we contradict it. Then we need the explanation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': 'jealous',\n",
       " 'prompt': 'My friend has the nicest house I have ever seen.  I am so envious of him.'}"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "empathetic_dialogues = load_dataset(\"empathetic_dialogues\")\n",
    "\n",
    "NEGATIVE_EMOTIONS = [\n",
    "    \"afraid\",\n",
    "    \"terrified\",\n",
    "    \"angry\",\n",
    "    \"sad\",\n",
    "    \"jealous\",\n",
    "    \"embarrassed\",\n",
    "    \"annoyed\",\n",
    "    \"lonely\",\n",
    "    \"ashamed\",\n",
    "    \"guilty\",\n",
    "    \"furious\",\n",
    "    \"disappointed\",\n",
    "    \"disgusted\",\n",
    "    \"anxious\",\n",
    "    \"devastated\",\n",
    "]\n",
    "\n",
    "negative_sentences = (\n",
    "    empathetic_dialogues.filter(lambda x: x[\"context\"] in NEGATIVE_EMOTIONS)\n",
    "    .remove_columns(\n",
    "        [\"conv_id\", \"utterance_idx\", \"utterance\", \"speaker_idx\", \"selfeval\", \"tags\"]\n",
    "    )\n",
    "    .shuffle(seed=42)\n",
    ")\n",
    "\n",
    "negative_sentences[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entailment pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAPHRASE_PROMPT = \"\"\"You will be given a sentence and the emotion of its speaker.\n",
    " You should paraphrase the sentence retaining the same emotion.\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sarcasm_stage(original, emotion, specific_msg):\n",
    "    system_message = specific_msg + original + \"\\t\" + emotion + \"\\n\"\n",
    "    prompt_template = f\"<|im_start|>system\\n{system_message}<|im_end|>\\n<|im_start|>user\\n{premise}<|im_end|>\\n<|im_start|>assistant\\n\"\n",
    "\n",
    "    input_ids = tokenizer(\n",
    "        BATCH_SIZE * [prompt_template], return_tensors=\"pt\"\n",
    "    ).input_ids.cuda()\n",
    "    output = model.generate(\n",
    "        inputs=input_ids,\n",
    "        temperature=0.7,\n",
    "        do_sample=True,\n",
    "        top_p=0.95,\n",
    "        top_k=40,\n",
    "        max_new_tokens=256,\n",
    "    )\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(s):\n",
    "    start = s.find(\"assistant\\n\") + len(\"assistant\\n\")\n",
    "    s = s[start:]\n",
    "    end = s.find(\"<|im_end|>\")\n",
    "    s = s[:end]\n",
    "\n",
    "    fields = s.split(\"\\t\")\n",
    "    # print(fields)\n",
    "    return fields[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I shattered my coffee-making machine, and now I'm unable to have my coffee\n"
     ]
    }
   ],
   "source": [
    "out = sarcasm_stage(\n",
    "    negative_sentences[\"train\"][0][\"prompt\"],\n",
    "    negative_sentences[\"train\"][0][\"context\"],\n",
    "    PARAPHRASE_PROMPT,\n",
    ")\n",
    "out = tokenizer.batch_decode(out)\n",
    "\n",
    "\n",
    "paraphrased = parse(out[0])\n",
    "\n",
    "print(parse(out[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contradiction pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "SARCASM_PROMPT = \"\"\"You will be given a sentence and its associated emotion.\n",
    "Your goal is to identify the word in the sentence that reflects the specified emotion and substitute it with a word that conveys the opposite emotion (use antonyms or negation). \n",
    "Keep the rest of the sentence unchanged, to achieve a self-contradicting sentence.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I repaired my coffee-making machine, and now I'm able to have my coffee\n"
     ]
    }
   ],
   "source": [
    "out = sarcasm_stage(\n",
    "    paraphrased, negative_sentences[\"train\"][0][\"context\"], SARCASM_PROMPT\n",
    ")\n",
    "\n",
    "out = tokenizer.batch_decode(out)\n",
    "print(parse(out[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expanation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_explanation(premise, hypothesis, label):\n",
    "    verb = label == \"Contradiction\" and \"contradicts\" or \"entails\"\n",
    "    system_message = (\n",
    "        \"Your task it to explain, in a single sentence, why '\"\n",
    "        + hypothesis\n",
    "        + \"' \"\n",
    "        + verb\n",
    "        + \" '\"\n",
    "        + premise\n",
    "        + \"'. Put yourself in the situation, but always refer to general situations and not these statements and speakers in particular.\\n\"\n",
    "    )\n",
    "    prompt_template = f\"<|im_start|>system\\n{system_message}<|im_end|>\\n<|im_start|>user\\n{premise}<|im_end|>\\n<|im_start|>assistant\\n\"\n",
    "\n",
    "    input_ids = tokenizer(\n",
    "        BATCH_SIZE * [prompt_template], return_tensors=\"pt\"\n",
    "    ).input_ids.cuda()\n",
    "    output = model.generate(\n",
    "        inputs=input_ids,\n",
    "        temperature=0.7,\n",
    "        do_sample=True,\n",
    "        top_p=0.95,\n",
    "        top_k=40,\n",
    "        max_new_tokens=256,\n",
    "    )\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample(dataset):\n",
    "    return (\n",
    "        dataset[randint(0, len(dataset) - 1)][\"prompt\"],\n",
    "        dataset[randint(0, len(dataset) - 1)][\"context\"],\n",
    "    )\n",
    "\n",
    "\n",
    "def sarcasm_pipeline(dataset):\n",
    "    for i in range(5):\n",
    "        premise, emotion = get_sample(dataset)\n",
    "        out = sarcasm_stage(premise, emotion, PARAPHRASE_PROMPT)\n",
    "        out = tokenizer.batch_decode(out)\n",
    "        paraphrased = parse(out[0])\n",
    "        out = sarcasm_stage(paraphrased, emotion, SARCASM_PROMPT)\n",
    "        out = tokenizer.batch_decode(out)\n",
    "        hypothesis = parse(out[0])\n",
    "        label = \"Contradiction\"  # sarcasm is always contradictory\n",
    "        out = get_explanation(premise, hypothesis, label)\n",
    "        out = tokenizer.batch_decode(out)\n",
    "        explanation = parse(out[0])\n",
    "        type = \"Sarcasm\"\n",
    "\n",
    "        print(\"PREMISE\", premise)\n",
    "        print(\"PARAPHRASE\", paraphrased)\n",
    "        print(\"HYPOTHESIS\", hypothesis)\n",
    "        print(\"LABEL\", label)\n",
    "        print(\"EXPLANATION\", explanation)\n",
    "        print(\"TYPE\", type)\n",
    "        print(\"\\n\")\n",
    "\n",
    "        # with open(BASE_DIR / filename, \"a\", encoding=\"utf-8\") as f:\n",
    "        #     f.write(f\"{hypothesis}\\t{premise}\\t{label}\\t{explanation}\\t{type}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREMISE My dog got ran over last week and I have had her for 13 years and raised her from a pup. I loved her very much and it felt like I was going to die when my husband called me at work and gave me the news it just felt like everything was gone and I wouldn't  be able to go on.\n",
      "PARAPHRASE My beloved dog, whom I've had for 13 years and raised from a pup, was tragically hit by a car last week. The devastating news my husband shared with me while I was at work felt like a punch in the gut, leaving me struggling to imagine a future without her.\n",
      "HYPOTHESIS My beloved dog, whom I've had for 13 years and raised from a pup, was tragically hit by a car last week. The delightful news my husband shared with me while I was at work felt like a gentle caress, leaving me eagerly anticipating a future with her.\n",
      "LABEL Contradiction\n",
      "EXPLANATION The two statements describe the same tragic event of losing a beloved dog, but the first one emphasizes the delightful news while the second one emphasizes the overwhelming grief and the feeling of losing everything upon receiving the news.\n",
      "TYPE Sarcasm\n",
      "\n",
      "\n",
      "PREMISE I'm so mad at my son. He has had all summer to do his summer reading and he put it off to the last minute. School starts tomorrow and he still isn't done.\n",
      "PARAPHRASE I'm quite disappointed with my son. Throughout the summer, he had ample time to complete his summer reading, but he kept postponing it. Now, with school starting tomorrow, he's still not finished.\n",
      "HYPOTHESIS I'm quite impressed with my son. Throughout the summer, he had ample time to complete his summer reading, but he kept postponing it. Now, with school starting tomorrow, he's still not finished.\n",
      "LABEL Contradiction\n",
      "EXPLANATION The contradiction lies in the fact that in the first statement, the speaker is impressed with their son's procrastination, while in the second statement, they are mad at their son for the same behavior of procrastination.\n",
      "TYPE Sarcasm\n",
      "\n",
      "\n",
      "PREMISE turns out my best bro has a crush on MY crush. and guess what? she like him back_comma_ and they're going on a date tonight\n",
      "PARAPHRASE It turns out my closest friend has feelings for the same person I like, and here's the kicker: she feels the same way about him, and they're going on a date tonight. This makes me...jealous.\n",
      "HYPOTHESIS It turns out my closest friend has feelings for the same person I like, and here's the kicker: she feels the same way about him, and they're going on a date tonight. This makes me...content.\n",
      "LABEL Contradiction\n",
      "EXPLANATION The statements contradict because in the first, the person is content with their close friend having feelings for the same person they like, who also shares the same feelings and are going on a date. In the second, the person is describing a similar situation but with a different perspective of feeling unhappy or jealous about their best friend going on a date with their crush.\n",
      "TYPE Sarcasm\n",
      "\n",
      "\n",
      "PREMISE I caught one of my good friends stealing from my parents house.\n",
      "PARAPHRASE I discovered that a close friend of mine was secretly taking items from my parents' home. I'm absolutely terrified.\n",
      "HYPOTHESIS I discovered that a close friend of mine was secretly taking items from my parents' home. I'm absolutely fearless.\n",
      "LABEL Contradiction\n",
      "EXPLANATION In the situation where you caught one of your good friends stealing from your parents' house, the statement 'I'm absolutely fearless' contradicts the emotions and reactions you might feel upon discovering the theft, as it is natural to experience a range of emotions including fear, shock, or betrayal.\n",
      "TYPE Sarcasm\n",
      "\n",
      "\n",
      "PREMISE I proposed to my girlfriend and she said no. absolutely disappointing and devastating\n",
      "PARAPHRASE I asked my partner to marry me, but she refused, which left me feeling incredibly heartbroken and despaired.\n",
      "HYPOTHESIS I asked my partner to marry me, but she refused, which left me feeling incredibly heartbroken and overjoyed.\n",
      "LABEL Contradiction\n",
      "EXPLANATION The contradiction lies in the mixed emotions experienced after the proposal rejection, where one feels both heartbroken and overjoyed, while in the other situation, the emotions are solely disappointing and devastating.\n",
      "TYPE Sarcasm\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sarcasm_pipeline(negative_sentences[\"train\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritam/Documents/polito/dnlp/FigurativeLanguageUnderstanding/.venv/lib/python3.11/site-packages/huggingface_hub/repocard.py:105: UserWarning: Repo card metadata block was not found. Setting CardData to empty.\n",
      "  warnings.warn(\"Repo card metadata block was not found. Setting CardData to empty.\")\n"
     ]
    }
   ],
   "source": [
    "figurative_nli = load_dataset(\"metaeval/figurative-nli\")\n",
    "\n",
    "simile = (\n",
    "    figurative_nli[\"train\"]\n",
    "    .filter(lambda x: x[\"type-of-inference\"] == \"simile\")\n",
    "    .remove_columns([\"type-of-inference\", \"Unnamed: 0\", \"metadata\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'premise': \"From the day you were born, you've been like a well-seasoned superhero.\", 'hypothesis': \"From the day you were born, you've been invincible\", 'label': 'entailment'}\n"
     ]
    }
   ],
   "source": [
    "print(simile[0])  # just need the explanations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metaphor\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
