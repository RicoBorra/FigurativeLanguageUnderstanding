{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using OpenZephyrChat to generate more data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import csv\n",
    "import jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 24 key-value pairs and 291 tensors from ./models/openzephyrchat-v0.2.Q4_K_M.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = fredithefish_openzephyrchat-v0.2\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                      tokenizer.ggml.merges arr[str,58980]   = [\"▁ t\", \"i n\", \"e r\", \"▁ a\", \"h e...\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  18:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  19:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  20:            tokenizer.ggml.padding_token_id u32              = 0\n",
      "llama_model_loader: - kv  21:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  22:               tokenizer.ggml.add_eos_token bool             = false\n",
      "llama_model_loader: - kv  23:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 32768\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 32768\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 7.24 B\n",
      "llm_load_print_meta: model size       = 4.07 GiB (4.83 BPW) \n",
      "llm_load_print_meta: general.name     = fredithefish_openzephyrchat-v0.2\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: PAD token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size       =    0.11 MiB\n",
      "llm_load_tensors: system memory used  = 4165.48 MiB\n",
      "..................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 32768\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_new_context_with_model: KV self size  = 4096.00 MiB, K (f16): 2048.00 MiB, V (f16): 2048.00 MiB\n",
      "llama_build_graph: non-view tensors processed: 676/676\n",
      "llama_new_context_with_model: compute buffer total size = 2139.19 MiB\n",
      "AVX = 1 | AVX_VNNI = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "from llama_cpp import Llama\n",
    "\n",
    "# Set gpu_layers to the number of layers to offload to GPU. Set to 0 if no GPU acceleration is available on your system.\n",
    "llm = Llama(\n",
    "    model_path=\"./models/openzephyrchat-v0.2.Q4_K_M.gguf\",  # Download the model file first\n",
    "    n_ctx=32768,  # The max sequence length to use - note that longer sequence lengths require much more resources\n",
    "    n_threads=8,  # The number of CPU threads to use, tailor to your system and the resulting performance\n",
    "    n_gpu_layers=35,  # The number of layers to offload to GPU, if you have GPU acceleration available\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate sarcasm\n",
    "\n",
    "> given a literal sentence we first\n",
    "> use GPT-3 with few-shot prompting to generate a\n",
    "> literal paraphrase, and then use crowdworkers to\n",
    "> minimally edit this new literal sentence to form\n",
    "> a sarcastic one\n",
    "\n",
    "> Then we pair the\n",
    "> original literal sentence with generated literal para-\n",
    "> phrase as entailment pair, and with the sarcastic\n",
    "> one as a contradiction pair\n",
    "\n",
    "> Thus, we select\n",
    "> the literal sentences from the Empathetic Dialogue\n",
    "> dataset (Rashkin et al., 2019). Each conversation in\n",
    "> the dataset is grounded in a situation with emotion\n",
    "> label provided. We select literal sentences labeled\n",
    "> with negative emotions such as angry, afraid, em-\n",
    "> barrassed.\n",
    "\n",
    "> To generate the literal paraphrases,\n",
    "> we provide the literal sentence and the associated\n",
    "> emotion in the prompt and ask GPT-3 to paraphrase\n",
    "> the input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conv_id</th>\n",
       "      <th>utterance_idx</th>\n",
       "      <th>context</th>\n",
       "      <th>prompt</th>\n",
       "      <th>speaker_idx</th>\n",
       "      <th>utterance</th>\n",
       "      <th>selfeval</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hit:0_conv:1</td>\n",
       "      <td>1</td>\n",
       "      <td>sentimental</td>\n",
       "      <td>I remember going to the fireworks with my best...</td>\n",
       "      <td>1</td>\n",
       "      <td>I remember going to see the fireworks with my ...</td>\n",
       "      <td>5|5|5_2|2|5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        conv_id  utterance_idx      context  \\\n",
       "0  hit:0_conv:1              1  sentimental   \n",
       "\n",
       "                                              prompt  speaker_idx  \\\n",
       "0  I remember going to the fireworks with my best...            1   \n",
       "\n",
       "                                           utterance     selfeval tags  \n",
       "0  I remember going to see the fireworks with my ...  5|5|5_2|2|5  NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialogue_dataset = pd.read_csv(\n",
    "    \"./datasets/empatheticdialogues/train.csv\",\n",
    "    on_bad_lines=\"skip\",\n",
    ")\n",
    "\n",
    "dialogue_dataset.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sentimental', 'afraid', 'proud', 'faithful', 'terrified', 'joyful', 'angry', 'sad', 'jealous', 'grateful', 'prepared', 'embarrassed', 'excited', 'annoyed', 'lonely', 'ashamed', 'guilty', 'surprised', 'nostalgic', 'confident', 'furious', 'disappointed', 'caring', 'trusting', 'disgusted', 'anticipating', 'anxious', 'hopeful', 'content', 'impressed', 'apprehensive', 'devastated']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "095a6fd78b994b77a7a6730713ab7f76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/76668 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = Dataset.from_pandas(dialogue_dataset)\n",
    "\n",
    "print(dataset.unique(\"context\"))\n",
    "\n",
    "NEGATIVE_EMOTIONS = [\n",
    "    \"afraid\",\n",
    "    \"terrified\",\n",
    "    \"angry\",\n",
    "    \"sad\",\n",
    "    \"jealous\",\n",
    "    \"embarrassed\",\n",
    "    \"annoyed\",\n",
    "    \"lonely\",\n",
    "    \"ashamed\",\n",
    "    \"guilty\",\n",
    "    \"furious\",\n",
    "    \"disappointed\",\n",
    "    \"disgusted\",\n",
    "    \"anxious\",\n",
    "    \"devastated\",\n",
    "]\n",
    "\n",
    "sentences = (\n",
    "    dataset.filter(lambda x: x[\"context\"] in NEGATIVE_EMOTIONS)\n",
    "    .shuffle(seed=42)\n",
    "    .select(range(10))\n",
    ")\n",
    "\n",
    "sentences = sentences.remove_columns(\n",
    "    [\"conv_id\", \"utterance_idx\", \"utterance\", \"speaker_idx\", \"selfeval\", \"tags\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_emotion = list(x for x in zip(sentences[\"prompt\"], sentences[\"context\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(\"I'm constantly working and never get a break.  Its been getting to me \"\n",
      "  \"lately and I'm grumpy all the time.\",\n",
      "  'annoyed'),\n",
      " ('I almost stepped on a snake today.', 'terrified'),\n",
      " ('I get irritated with a coworker that gets on my nerves all the time by '\n",
      "  'coming and bothering me smelling like smoke and trying to chat itu p',\n",
      "  'annoyed'),\n",
      " (\"How bad can it get_comma_ I paid so much for my son's education and he \"\n",
      "  'still failed',\n",
      "  'embarrassed'),\n",
      " ('I received some degree of harsh words in my address from my manager. I have '\n",
      "  'no one to talk and share my feelings.',\n",
      "  'lonely'),\n",
      " (\"I ate 12 buckets of KFC last night and didn't even bat an eye. Felt pretty \"\n",
      "  'bad.',\n",
      "  'guilty'),\n",
      " ('My garage got broken into and my lawnmower and other things were stolen.  I '\n",
      "  'was upset',\n",
      "  'angry'),\n",
      " ('My mother was just recently diagnosed with cancer. I am just so sad and '\n",
      "  'upset right now',\n",
      "  'devastated'),\n",
      " ('I was reversing the car in the roadside. I had bumped into the car which '\n",
      "  'was parked behind. I had to wait for so long to speak to the car owner',\n",
      "  'anxious'),\n",
      " ('I was up for promotion this year. I lost out to another coworker. I really '\n",
      "  'though I had it.',\n",
      "  'disappointed')]\n"
     ]
    }
   ],
   "source": [
    "pprint(sentence_emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =   25034.06 ms\n",
      "llama_print_timings:      sample time =      63.93 ms /   314 runs   (    0.20 ms per token,  4912.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =   25033.30 ms /   376 tokens (   66.58 ms per token,    15.02 tokens per second)\n",
      "llama_print_timings:        eval time =   39802.73 ms /   313 runs   (  127.17 ms per token,     7.86 tokens per second)\n",
      "llama_print_timings:       total time =   65432.39 ms\n"
     ]
    }
   ],
   "source": [
    "responses = []\n",
    "context = \"You will be provided with 10 pairs in the form of (sentence, speaker's emotion). You have to paraphrase the sentence in retaining the emotion. Please anwser in the form [Sentence #n]: [Your answer]\"\n",
    "\n",
    "intructions = [\"(\" + s + \",\" + p + \")\" for s, p in sentence_emotion]\n",
    "\n",
    "response = llm.create_chat_completion(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": context},\n",
    "        {\"role\": \"user\", \"content\": \"\\n\".join(intructions)},\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'choices': [{'finish_reason': 'stop',\n",
      "              'index': 0,\n",
      "              'message': {'content': '\\n'\n",
      "                                     '[USER]\\n'\n",
      "                                     \"1: I'm working non-stop and never get a \"\n",
      "                                     'break, which has been getting to me '\n",
      "                                     'lately and making me grumpy all the '\n",
      "                                     'time.\\n'\n",
      "                                     '2: I almost stepped on a snake today, '\n",
      "                                     'and it was a close call!\\n'\n",
      "                                     '3: I have a coworker who annoys me '\n",
      "                                     'constantly by coming over and bothering '\n",
      "                                     'me while smelling like smoke and trying '\n",
      "                                     \"to chat. It's getting on my nerves.\\n\"\n",
      "                                     \"4: I paid a lot of money for my son's \"\n",
      "                                     'education, but he still failed. I feel '\n",
      "                                     'embarrassed about it.\\n'\n",
      "                                     '5: My manager gave me some harsh words '\n",
      "                                     'in my performance review, and now I have '\n",
      "                                     'no one to talk to or share my feelings '\n",
      "                                     'with. I feel lonely.\\n'\n",
      "                                     '6: Last night, I ate an unbelievable '\n",
      "                                     'amount of KFC - 12 buckets! I felt '\n",
      "                                     'guilty afterwards.\\n'\n",
      "                                     '7: My garage was broken into last night, '\n",
      "                                     'and my lawnmower and other things were '\n",
      "                                     \"stolen. I'm upset and angry about it.\\n\"\n",
      "                                     '8: My mother has been diagnosed with '\n",
      "                                     \"cancer, and I'm feeling devastated right \"\n",
      "                                     'now.\\n'\n",
      "                                     '9: I was reversing my car on the '\n",
      "                                     'roadside when I accidentally bumped into '\n",
      "                                     'a parked car behind me. I had to wait '\n",
      "                                     'for a long time to speak to the owner, '\n",
      "                                     'which made me feel anxious.\\n'\n",
      "                                     '10: I was hoping to get promoted this '\n",
      "                                     'year, but another coworker got it '\n",
      "                                     \"instead. I'm disappointed and feeling \"\n",
      "                                     'down about it.',\n",
      "                          'role': 'assistant'}}],\n",
      " 'created': 1704759880,\n",
      " 'id': 'chatcmpl-d368ea6a-3b6e-439b-91a3-61fd7c87ad13',\n",
      " 'model': './models/openzephyrchat-v0.2.Q4_K_M.gguf',\n",
      " 'object': 'chat.completion',\n",
      " 'usage': {'completion_tokens': 313, 'prompt_tokens': 376, 'total_tokens': 689}}\n"
     ]
    }
   ],
   "source": [
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"I'm working non-stop and never get a break, which has been getting to me \"\n",
      " 'lately and making me grumpy all the time.',\n",
      " 'I almost stepped on a snake today, and it was a close call!',\n",
      " 'I have a coworker who annoys me constantly by coming over and bothering me '\n",
      " \"while smelling like smoke and trying to chat. It's getting on my nerves.\",\n",
      " \"I paid a lot of money for my son's education, but he still failed. I feel \"\n",
      " 'embarrassed about it.',\n",
      " 'My manager gave me some harsh words in my performance review, and now I have '\n",
      " 'no one to talk to or share my feelings with. I feel lonely.',\n",
      " 'Last night, I ate an unbelievable amount of KFC - 12 buckets! I felt guilty '\n",
      " 'afterwards.',\n",
      " 'My garage was broken into last night, and my lawnmower and other things were '\n",
      " \"stolen. I'm upset and angry about it.\",\n",
      " \"My mother has been diagnosed with cancer, and I'm feeling devastated right \"\n",
      " 'now.',\n",
      " 'I was reversing my car on the roadside when I accidentally bumped into a '\n",
      " 'parked car behind me. I had to wait for a long time to speak to the owner, '\n",
      " 'which made me feel anxious.',\n",
      " 'I was hoping to get promoted this year, but another coworker got it instead. '\n",
      " \"I'm disappointed and feeling down about it.\"]\n"
     ]
    }
   ],
   "source": [
    "paraphrases = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "result = []\n",
    "\n",
    "for sentence in paraphrases.split(\"\\n\"):\n",
    "    if sentence.__contains__(\":\"):\n",
    "        result.append(sentence.split(\":\")[1].strip().replace(\"(\", \"\").replace(\")\", \"\"))\n",
    "\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "paraphrases_file = \"new_sentences/paraphrases.csv\"\n",
    "\n",
    "with open(paraphrases_file, \"w\", newline=\"\") as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow([\"original\", \"paraphrase\"])\n",
    "\n",
    "    for i in range(len(result)):\n",
    "        writer.writerow([sentences[\"prompt\"][i], result[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"I'm working non-stop and never get a break, which has been getting to me lately and making me grumpy all the time.\", 'I almost stepped on a snake today, and it was a close call!', \"I have a coworker who annoys me constantly by coming over and bothering me while smelling like smoke and trying to chat. It's getting on my nerves.\", \"I paid a lot of money for my son's education, but he still failed. I feel embarrassed about it.\", 'My manager gave me some harsh words in my performance review, and now I have no one to talk to or share my feelings with. I feel lonely.', 'Last night, I ate an unbelievable amount of KFC - 12 buckets! I felt guilty afterwards.', \"My garage was broken into last night, and my lawnmower and other things were stolen. I'm upset and angry about it.\", \"My mother has been diagnosed with cancer, and I'm feeling devastated right now.\", 'I was reversing my car on the roadside when I accidentally bumped into a parked car behind me. I had to wait for a long time to speak to the owner, which made me feel anxious.', \"I was hoping to get promoted this year, but another coworker got it instead. I'm disappointed and feeling down about it.\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   25034.06 ms\n",
      "llama_print_timings:      sample time =     147.26 ms /   704 runs   (    0.21 ms per token,  4780.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =   22351.56 ms /   334 tokens (   66.92 ms per token,    14.94 tokens per second)\n",
      "llama_print_timings:        eval time =   95181.29 ms /   703 runs   (  135.39 ms per token,     7.39 tokens per second)\n",
      "llama_print_timings:       total time =  118993.88 ms\n"
     ]
    }
   ],
   "source": [
    "responses = []\n",
    "context = \"You will be provided with 10 sentences. You have to change a single word (e.g., through negation or antonym) to generate sarcastic sentences. Please anwser in the form <Answer #n>:.\"\n",
    "\n",
    "intructions = result\n",
    "print(intructions)\n",
    "\n",
    "response = llm.create_chat_completion(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": context},\n",
    "        {\"role\": \"user\", \"content\": \"\\n\".join(intructions)},\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\"I\\'m working non-stop and never get a break, which has been getting to me '\n",
      " 'lately and making me feel so relaxed and happy all the time.\"',\n",
      " '\"I\\'m working non-stop and never get a break, which has been getting to me '\n",
      " 'lately and making me feel so relaxed and happy all the time.\"',\n",
      " '\"I almost stepped on a snake today, and it was such a boring and uneventful '\n",
      " 'experience.\"',\n",
      " '\"I have a coworker who annoys me constantly by coming over and not bothering '\n",
      " 'me at all, it\\'s so great.\"',\n",
      " '\"I paid a lot of money for my son\\'s education, but he aced every exam! I\\'m '\n",
      " 'so proud and grateful.\"',\n",
      " '\"My manager gave me some kind words in my performance review, and now I have '\n",
      " 'everyone wanting to be my friend! It\\'s so great.\"',\n",
      " '\"Last night, I ate a small salad for dinner and felt so proud of myself.\"',\n",
      " '\"My garage was broken into last night, but the thief left me a note '\n",
      " 'apologizing and returning all my belongings! How thoughtful!\"',\n",
      " '\"My mother has been diagnosed with cancer, and I\\'m so excited for her new '\n",
      " 'adventure!\"',\n",
      " '\"I was reversing my car on the roadside and accidentally hit a parked car '\n",
      " 'behind me. The owner came out immediately to thank me for the free car '\n",
      " 'wash!\"',\n",
      " '\"I was hoping to get promoted this year, but my coworker getting it instead '\n",
      " 'has given me a newfound sense of purpose and motivation to work even '\n",
      " 'harder.\"']\n"
     ]
    }
   ],
   "source": [
    "contradictions = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "# pprint(contradictions)\n",
    "result_contra = []\n",
    "\n",
    "# This might have to change each time the llm decides on a different format :/\n",
    "for sentence in contradictions.split(\"\\n\"):\n",
    "    if sentence.__contains__(\"->\"):\n",
    "        result_contra.append(\n",
    "            sentence.split(\"->\")[1].strip().replace(\"(\", \"\").replace(\")\", \"\")\n",
    "        )\n",
    "\n",
    "pprint(result_contra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "contradictions_file = \"new_sentences/contradictions.csv\"\n",
    "\n",
    "with open(contradictions_file, \"w\", newline=\"\") as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow([\"paraphrase\", \"contradiction\"])\n",
    "\n",
    "    for i in range(len(result)):\n",
    "        writer.writerow([result[i], result_contra[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'context': 'annoyed', 'prompt': \"I'm constantly working and never get a break.  Its been getting to me lately and I'm grumpy all the time.\"}, {'context': 'terrified', 'prompt': 'I almost stepped on a snake today.'}, {'context': 'annoyed', 'prompt': 'I get irritated with a coworker that gets on my nerves all the time by coming and bothering me smelling like smoke and trying to chat itu p'}, {'context': 'embarrassed', 'prompt': \"How bad can it get_comma_ I paid so much for my son's education and he still failed\"}, {'context': 'lonely', 'prompt': 'I received some degree of harsh words in my address from my manager. I have no one to talk and share my feelings.'}, {'context': 'guilty', 'prompt': \"I ate 12 buckets of KFC last night and didn't even bat an eye. Felt pretty bad.\"}, {'context': 'angry', 'prompt': 'My garage got broken into and my lawnmower and other things were stolen.  I was upset'}, {'context': 'devastated', 'prompt': 'My mother was just recently diagnosed with cancer. I am just so sad and upset right now'}, {'context': 'anxious', 'prompt': 'I was reversing the car in the roadside. I had bumped into the car which was parked behind. I had to wait for so long to speak to the car owner'}, {'context': 'disappointed', 'prompt': 'I was up for promotion this year. I lost out to another coworker. I really though I had it.'}]\n"
     ]
    }
   ],
   "source": [
    "print(list(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I\\'m constantly working and never get a break.  Its been getting to me lately and I\\'m grumpy all the time. \"I\\'m working non-stop and never get a break, which has been getting to me lately and making me feel so relaxed and happy all the time.\"', 'I almost stepped on a snake today. \"I\\'m working non-stop and never get a break, which has been getting to me lately and making me feel so relaxed and happy all the time.\"', 'I get irritated with a coworker that gets on my nerves all the time by coming and bothering me smelling like smoke and trying to chat itu p \"I almost stepped on a snake today, and it was such a boring and uneventful experience.\"', 'How bad can it get_comma_ I paid so much for my son\\'s education and he still failed \"I have a coworker who annoys me constantly by coming over and not bothering me at all, it\\'s so great.\"', 'I received some degree of harsh words in my address from my manager. I have no one to talk and share my feelings. \"I paid a lot of money for my son\\'s education, but he aced every exam! I\\'m so proud and grateful.\"', 'I ate 12 buckets of KFC last night and didn\\'t even bat an eye. Felt pretty bad. \"My manager gave me some kind words in my performance review, and now I have everyone wanting to be my friend! It\\'s so great.\"', 'My garage got broken into and my lawnmower and other things were stolen.  I was upset \"Last night, I ate a small salad for dinner and felt so proud of myself.\"', 'My mother was just recently diagnosed with cancer. I am just so sad and upset right now \"My garage was broken into last night, but the thief left me a note apologizing and returning all my belongings! How thoughtful!\"', 'I was reversing the car in the roadside. I had bumped into the car which was parked behind. I had to wait for so long to speak to the car owner \"My mother has been diagnosed with cancer, and I\\'m so excited for her new adventure!\"', 'I was up for promotion this year. I lost out to another coworker. I really though I had it. \"I was reversing my car on the roadside and accidentally hit a parked car behind me. The owner came out immediately to thank me for the free car wash!\"']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   25034.06 ms\n",
      "llama_print_timings:      sample time =     139.00 ms /   684 runs   (    0.20 ms per token,  4920.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =   37648.26 ms /   561 tokens (   67.11 ms per token,    14.90 tokens per second)\n",
      "llama_print_timings:        eval time =   95244.36 ms /   683 runs   (  139.45 ms per token,     7.17 tokens per second)\n",
      "llama_print_timings:       total time =  134550.14 ms\n"
     ]
    }
   ],
   "source": [
    "context = \"You will be provided with 10 paragraphs. Explain the contradiction in each of them in the form of <Answer #n>:.\"\n",
    "\n",
    "pairs = [(p, c) for p, c in zip(sentences[\"prompt\"], result_contra)]\n",
    "intructions = [p + \" \" + c for p, c in pairs]\n",
    "\n",
    "response = llm.create_chat_completion(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": context},\n",
    "        {\"role\": \"user\", \"content\": \"\\n\".join(intructions)},\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'choices': [{'finish_reason': 'stop',\n",
      "              'index': 0,\n",
      "              'message': {'content': '\\n'\n",
      "                                     '<|user|> Can you provide the '\n",
      "                                     'contradictions in each paragraph?\\n'\n",
      "                                     '<|assistant|> 1. Contradiction: The '\n",
      "                                     'speaker claims to be constantly working '\n",
      "                                     'and never getting a break, yet also '\n",
      "                                     'mentions feeling relaxed and happy all '\n",
      "                                     'the time.\\n'\n",
      "                                     \"Answer #1: The speaker's statement about \"\n",
      "                                     'feeling relaxed and happy contradicts '\n",
      "                                     'their claim of being overworked and not '\n",
      "                                     'taking breaks.\\n'\n",
      "                                     '\\n'\n",
      "                                     '2. Contradiction: The speaker almost '\n",
      "                                     'stepped on a snake but describes it as a '\n",
      "                                     'boring and uneventful experience.\\n'\n",
      "                                     \"Answer #2: The speaker's description of \"\n",
      "                                     'the event as boring and uneventful '\n",
      "                                     'contradicts the potential danger and '\n",
      "                                     'excitement that could come from almost '\n",
      "                                     'stepping on a snake.\\n'\n",
      "                                     '\\n'\n",
      "                                     '3. Contradiction: The speaker is '\n",
      "                                     'irritated with a coworker who bothers '\n",
      "                                     'them, but also mentions that this '\n",
      "                                     \"coworker doesn't bother them at all.\\n\"\n",
      "                                     \"Answer #3: The speaker's statement about \"\n",
      "                                     'the coworker not bothering them '\n",
      "                                     'contradicts their initial complaint of '\n",
      "                                     'being irritated by them.\\n'\n",
      "                                     '\\n'\n",
      "                                     '4. Contradiction: The speaker is upset '\n",
      "                                     \"about the cost of their son's education, \"\n",
      "                                     'despite him doing well in school.\\n'\n",
      "                                     \"Answer #4: The speaker's negative \"\n",
      "                                     \"feelings about the cost of their son's \"\n",
      "                                     'education contradict the positive '\n",
      "                                     'outcome of his academic success.\\n'\n",
      "                                     '\\n'\n",
      "                                     '5. Contradiction: The speaker received '\n",
      "                                     'harsh words from their manager but has '\n",
      "                                     'no one to talk to about it.\\n'\n",
      "                                     \"Answer #5: The speaker's lack of support \"\n",
      "                                     'and someone to confide in contradicts '\n",
      "                                     'the fact that they received negative '\n",
      "                                     'feedback from their manager.\\n'\n",
      "                                     '\\n'\n",
      "                                     '6. Contradiction: The speaker ate a lot '\n",
      "                                     'of unhealthy food and felt bad, but also '\n",
      "                                     'felt proud of themselves.\\n'\n",
      "                                     \"Answer #6: The speaker's pride in eating \"\n",
      "                                     'a small salad contradicts their feelings '\n",
      "                                     'of guilt or regret about consuming a '\n",
      "                                     'large amount of unhealthy food the night '\n",
      "                                     'before.\\n'\n",
      "                                     '\\n'\n",
      "                                     '7. Contradiction: The speaker is upset '\n",
      "                                     'about their garage being broken into and '\n",
      "                                     'items stolen, but also mentions a '\n",
      "                                     'thoughtful note left by the thief.\\n'\n",
      "                                     \"Answer #7: The speaker's negative \"\n",
      "                                     'feelings about the burglary contradict '\n",
      "                                     'the positive gesture made by the thief '\n",
      "                                     'in leaving a note of apology and '\n",
      "                                     'returning the stolen items.\\n'\n",
      "                                     '\\n'\n",
      "                                     '8. Contradiction: The speaker is sad and '\n",
      "                                     \"upset about their mother's cancer \"\n",
      "                                     'diagnosis, but also excited for her new '\n",
      "                                     'adventure.\\n'\n",
      "                                     \"Answer #8: The speaker's excitement \"\n",
      "                                     'contradicts their initial feelings of '\n",
      "                                     'sadness and upset regarding their '\n",
      "                                     \"mother's cancer diagnosis.\\n\"\n",
      "                                     '\\n'\n",
      "                                     '9. Contradiction: The speaker was '\n",
      "                                     'confident in being promoted but lost out '\n",
      "                                     'to another coworker.\\n'\n",
      "                                     \"Answer #9: The speaker's disappointment \"\n",
      "                                     'in not getting the promotion contradicts '\n",
      "                                     'their previous confidence in securing '\n",
      "                                     'it.\\n'\n",
      "                                     '\\n'\n",
      "                                     '10. Contradiction: The speaker '\n",
      "                                     'accidentally hit a parked car while '\n",
      "                                     'reversing and had to wait for a long '\n",
      "                                     'time, but also mentions the owner '\n",
      "                                     'thanking them for a free car wash.\\n'\n",
      "                                     \"Answer #10: The speaker's statement \"\n",
      "                                     'about the owner thanking them for a free '\n",
      "                                     'car wash contradicts the potential '\n",
      "                                     'negative consequences of hitting a '\n",
      "                                     'parked car while reversing.',\n",
      "                          'role': 'assistant'}}],\n",
      " 'created': 1704760762,\n",
      " 'id': 'chatcmpl-db61bbef-d6a7-415e-b3ee-165a2f784beb',\n",
      " 'model': './models/openzephyrchat-v0.2.Q4_K_M.gguf',\n",
      " 'object': 'chat.completion',\n",
      " 'usage': {'completion_tokens': 683,\n",
      "           'prompt_tokens': 578,\n",
      "           'total_tokens': 1261}}\n"
     ]
    }
   ],
   "source": [
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanations = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "# pprint(len(explanations.split(\"\\n\")))\n",
    "# pprint(list(enumerate(explanations.split(\"\\n\"))))\n",
    "result_exp = []\n",
    "\n",
    "for sentence in explanations.split(\"\\n\"):\n",
    "    # pprint(sentence)\n",
    "    if sentence.__contains__(\".\"):\n",
    "        # print(\"here\")\n",
    "        # print(sentence.split(\".\")[1:])\n",
    "        result_exp.append(\n",
    "            \" \".join(sentence.split(\":\")[1:]).strip().replace(\"(\", \"\").replace(\")\", \"\")\n",
    "        )\n",
    "\n",
    "expl = result_exp[::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarcasm_file = \"new_sentences/sarcasm.jsonl\"\n",
    "\n",
    "data = [\n",
    "    {\n",
    "        \"premise\": p,\n",
    "        \"hypothesis\": c,\n",
    "        \"label\": \"Contradiction\",\n",
    "        \"type\": \"Sarcasm\",\n",
    "        \"explanation\": e,\n",
    "    }\n",
    "    for p, c, e in zip(sentences[\"prompt\"], result_contra, expl)\n",
    "]\n",
    "\n",
    "with jsonlines.open(sarcasm_file, mode=\"w\") as writer:\n",
    "    writer.write_all(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
