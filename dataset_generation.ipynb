{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using OpenZephyrChat to generate more data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 24 key-value pairs and 291 tensors from ./models/openzephyrchat-v0.2.Q4_K_M.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = fredithefish_openzephyrchat-v0.2\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                      tokenizer.ggml.merges arr[str,58980]   = [\"▁ t\", \"i n\", \"e r\", \"▁ a\", \"h e...\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  18:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  19:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  20:            tokenizer.ggml.padding_token_id u32              = 0\n",
      "llama_model_loader: - kv  21:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  22:               tokenizer.ggml.add_eos_token bool             = false\n",
      "llama_model_loader: - kv  23:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 32768\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 32768\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 7.24 B\n",
      "llm_load_print_meta: model size       = 4.07 GiB (4.83 BPW) \n",
      "llm_load_print_meta: general.name     = fredithefish_openzephyrchat-v0.2\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: PAD token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size       =    0.11 MiB\n",
      "llm_load_tensors: system memory used  = 4165.48 MiB\n",
      "..................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 32768\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_new_context_with_model: KV self size  = 4096.00 MiB, K (f16): 2048.00 MiB, V (f16): 2048.00 MiB\n",
      "llama_build_graph: non-view tensors processed: 676/676\n",
      "llama_new_context_with_model: compute buffer total size = 2139.19 MiB\n",
      "AVX = 1 | AVX_VNNI = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "from llama_cpp import Llama\n",
    "\n",
    "# Set gpu_layers to the number of layers to offload to GPU. Set to 0 if no GPU acceleration is available on your system.\n",
    "llm = Llama(\n",
    "    model_path=\"./models/openzephyrchat-v0.2.Q4_K_M.gguf\",  # Download the model file first\n",
    "    n_ctx=32768,  # The max sequence length to use - note that longer sequence lengths require much more resources\n",
    "    n_threads=8,  # The number of CPU threads to use, tailor to your system and the resulting performance\n",
    "    n_gpu_layers=35,  # The number of layers to offload to GPU, if you have GPU acceleration available\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate sarcasm\n",
    "\n",
    "> given a literal sentence we first\n",
    "> use GPT-3 with few-shot prompting to generate a\n",
    "> literal paraphrase, and then use crowdworkers to\n",
    "> minimally edit this new literal sentence to form\n",
    "> a sarcastic one\n",
    "\n",
    "> Then we pair the\n",
    "> original literal sentence with generated literal para-\n",
    "> phrase as entailment pair, and with the sarcastic\n",
    "> one as a contradiction pair\n",
    "\n",
    "> Thus, we select\n",
    "> the literal sentences from the Empathetic Dialogue\n",
    "> dataset (Rashkin et al., 2019). Each conversation in\n",
    "> the dataset is grounded in a situation with emotion\n",
    "> label provided. We select literal sentences labeled\n",
    "> with negative emotions such as angry, afraid, em-\n",
    "> barrassed.\n",
    "\n",
    "> To generate the literal paraphrases,\n",
    "> we provide the literal sentence and the associated\n",
    "> emotion in the prompt and ask GPT-3 to paraphrase\n",
    "> the input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conv_id</th>\n",
       "      <th>utterance_idx</th>\n",
       "      <th>context</th>\n",
       "      <th>prompt</th>\n",
       "      <th>speaker_idx</th>\n",
       "      <th>utterance</th>\n",
       "      <th>selfeval</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hit:0_conv:1</td>\n",
       "      <td>1</td>\n",
       "      <td>sentimental</td>\n",
       "      <td>I remember going to the fireworks with my best...</td>\n",
       "      <td>1</td>\n",
       "      <td>I remember going to see the fireworks with my ...</td>\n",
       "      <td>5|5|5_2|2|5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        conv_id  utterance_idx      context  \\\n",
       "0  hit:0_conv:1              1  sentimental   \n",
       "\n",
       "                                              prompt  speaker_idx  \\\n",
       "0  I remember going to the fireworks with my best...            1   \n",
       "\n",
       "                                           utterance     selfeval tags  \n",
       "0  I remember going to see the fireworks with my ...  5|5|5_2|2|5  NaN  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialogue_dataset = pd.read_csv(\n",
    "    \"./datasets/empatheticdialogues/train.csv\",\n",
    "    on_bad_lines=\"skip\",\n",
    ")\n",
    "\n",
    "dialogue_dataset.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sentimental', 'afraid', 'proud', 'faithful', 'terrified', 'joyful', 'angry', 'sad', 'jealous', 'grateful', 'prepared', 'embarrassed', 'excited', 'annoyed', 'lonely', 'ashamed', 'guilty', 'surprised', 'nostalgic', 'confident', 'furious', 'disappointed', 'caring', 'trusting', 'disgusted', 'anticipating', 'anxious', 'hopeful', 'content', 'impressed', 'apprehensive', 'devastated']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b6d1abf8d644766bb93769b6bf4bb28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/76668 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = Dataset.from_pandas(dialogue_dataset)\n",
    "\n",
    "print(dataset.unique(\"context\"))\n",
    "\n",
    "NEGATIVE_EMOTIONS = [\n",
    "    \"afraid\",\n",
    "    \"terrified\",\n",
    "    \"angry\",\n",
    "    \"sad\",\n",
    "    \"jealous\",\n",
    "    \"embarrassed\",\n",
    "    \"annoyed\",\n",
    "    \"lonely\",\n",
    "    \"ashamed\",\n",
    "    \"guilty\",\n",
    "    \"furious\",\n",
    "    \"disappointed\",\n",
    "    \"disgusted\",\n",
    "    \"anxious\",\n",
    "    \"devastated\",\n",
    "]\n",
    "\n",
    "sentences = (\n",
    "    dataset.filter(lambda x: x[\"context\"] in NEGATIVE_EMOTIONS)\n",
    "    .shuffle(seed=42)\n",
    "    .select(range(10))\n",
    ")\n",
    "\n",
    "sentences = sentences.remove_columns(\n",
    "    [\"conv_id\", \"utterance_idx\", \"utterance\", \"speaker_idx\", \"selfeval\", \"tags\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_emotion = list(x for x in zip(sentences[\"prompt\"], sentences[\"context\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(\"I'm constantly working and never get a break.  Its been getting to me \"\n",
      "  \"lately and I'm grumpy all the time.\",\n",
      "  'annoyed'),\n",
      " ('I almost stepped on a snake today.', 'terrified'),\n",
      " ('I get irritated with a coworker that gets on my nerves all the time by '\n",
      "  'coming and bothering me smelling like smoke and trying to chat itu p',\n",
      "  'annoyed'),\n",
      " (\"How bad can it get_comma_ I paid so much for my son's education and he \"\n",
      "  'still failed',\n",
      "  'embarrassed'),\n",
      " ('I received some degree of harsh words in my address from my manager. I have '\n",
      "  'no one to talk and share my feelings.',\n",
      "  'lonely'),\n",
      " (\"I ate 12 buckets of KFC last night and didn't even bat an eye. Felt pretty \"\n",
      "  'bad.',\n",
      "  'guilty'),\n",
      " ('My garage got broken into and my lawnmower and other things were stolen.  I '\n",
      "  'was upset',\n",
      "  'angry'),\n",
      " ('My mother was just recently diagnosed with cancer. I am just so sad and '\n",
      "  'upset right now',\n",
      "  'devastated'),\n",
      " ('I was reversing the car in the roadside. I had bumped into the car which '\n",
      "  'was parked behind. I had to wait for so long to speak to the car owner',\n",
      "  'anxious'),\n",
      " ('I was up for promotion this year. I lost out to another coworker. I really '\n",
      "  'though I had it.',\n",
      "  'disappointed')]\n"
     ]
    }
   ],
   "source": [
    "pprint(sentence_emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    9047.00 ms\n",
      "llama_print_timings:      sample time =      62.82 ms /   312 runs   (    0.20 ms per token,  4966.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =   23636.81 ms /   361 tokens (   65.48 ms per token,    15.27 tokens per second)\n",
      "llama_print_timings:        eval time =   41571.81 ms /   311 runs   (  133.67 ms per token,     7.48 tokens per second)\n",
      "llama_print_timings:       total time =   65793.03 ms\n"
     ]
    }
   ],
   "source": [
    "responses = []\n",
    "context = \"You will be provided with 10 pairs in the form of (sentence, speaker's emotion). You have to paraphrase the sentence in retaining the emotion. Please anwser in the form [Sentence #n]: [Your answer]\"\n",
    "\n",
    "intructions = [\"(\" + s + \",\" + p + \")\" for s, p in sentence_emotion]\n",
    "\n",
    "response = llm.create_chat_completion(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": context},\n",
    "        {\"role\": \"user\", \"content\": \"\\n\".join(intructions)},\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'choices': [{'finish_reason': 'stop',\n",
      "              'index': 0,\n",
      "              'message': {'content': '\\n'\n",
      "                                     '[USER]\\n'\n",
      "                                     \"1: I'm working non-stop and never get a \"\n",
      "                                     'break, which is starting to wear me down '\n",
      "                                     'and make me grumpy all the time.\\n'\n",
      "                                     '2: I almost stepped on a snake today, '\n",
      "                                     'which gave me quite a scare.\\n'\n",
      "                                     '3: A coworker of mine keeps bothering '\n",
      "                                     'me, always coming over and chatting when '\n",
      "                                     \"I'm trying to work, and it's really \"\n",
      "                                     'starting to get on my nerves.\\n'\n",
      "                                     \"4: I spent a lot of money on my son's \"\n",
      "                                     \"education, but he still failed. It's \"\n",
      "                                     'embarrassing.\\n'\n",
      "                                     '5: My manager criticized me pretty '\n",
      "                                     'harshly in front of others, and now I '\n",
      "                                     \"feel lonely because I don't have anyone \"\n",
      "                                     'to talk to about it.\\n'\n",
      "                                     '6: Last night, I ate an unbelievable '\n",
      "                                     \"amount of KFC and didn't even flinch. \"\n",
      "                                     'Now I feel guilty about it.\\n'\n",
      "                                     '7: My garage was broken into last night, '\n",
      "                                     'and my lawnmower and other things were '\n",
      "                                     \"stolen. I'm really angry about it.\\n\"\n",
      "                                     '8: My mother has been diagnosed with '\n",
      "                                     \"cancer, and I'm feeling devastated right \"\n",
      "                                     'now.\\n'\n",
      "                                     '9: I was backing up the car on the '\n",
      "                                     'roadside when I accidentally hit a '\n",
      "                                     'parked car behind me. I had to wait for '\n",
      "                                     'a long time to speak to the owner, which '\n",
      "                                     'made me feel anxious.\\n'\n",
      "                                     '10: I was hoping to get promoted this '\n",
      "                                     'year, but another coworker got it '\n",
      "                                     \"instead. It's really disappointing.\",\n",
      "                          'role': 'assistant'}}],\n",
      " 'created': 1704743694,\n",
      " 'id': 'chatcmpl-1fd1685d-a82b-45bf-9854-b4a1631d8ef3',\n",
      " 'model': './models/openzephyrchat-v0.2.Q4_K_M.gguf',\n",
      " 'object': 'chat.completion',\n",
      " 'usage': {'completion_tokens': 311, 'prompt_tokens': 376, 'total_tokens': 687}}\n"
     ]
    }
   ],
   "source": [
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[USER]\n",
      "1: I'm working non-stop and never get a break, which is starting to wear me down and make me grumpy all the time.\n",
      "2: I almost stepped on a snake today, which gave me quite a scare.\n",
      "3: A coworker of mine keeps bothering me, always coming over and chatting when I'm trying to work, and it's really starting to get on my nerves.\n",
      "4: I spent a lot of money on my son's education, but he still failed. It's embarrassing.\n",
      "5: My manager criticized me pretty harshly in front of others, and now I feel lonely because I don't have anyone to talk to about it.\n",
      "6: Last night, I ate an unbelievable amount of KFC and didn't even flinch. Now I feel guilty about it.\n",
      "7: My garage was broken into last night, and my lawnmower and other things were stolen. I'm really angry about it.\n",
      "8: My mother has been diagnosed with cancer, and I'm feeling devastated right now.\n",
      "9: I was backing up the car on the roadside when I accidentally hit a parked car behind me. I had to wait for a long time to speak to the owner, which made me feel anxious.\n",
      "10: I was hoping to get promoted this year, but another coworker got it instead. It's really disappointing.\n",
      "[\"I'm working non-stop and never get a break, which is starting to wear me down and make me grumpy all the time.\", 'I almost stepped on a snake today, which gave me quite a scare.', \"A coworker of mine keeps bothering me, always coming over and chatting when I'm trying to work, and it's really starting to get on my nerves.\", \"I spent a lot of money on my son's education, but he still failed. It's embarrassing.\", \"My manager criticized me pretty harshly in front of others, and now I feel lonely because I don't have anyone to talk to about it.\", \"Last night, I ate an unbelievable amount of KFC and didn't even flinch. Now I feel guilty about it.\", \"My garage was broken into last night, and my lawnmower and other things were stolen. I'm really angry about it.\", \"My mother has been diagnosed with cancer, and I'm feeling devastated right now.\", 'I was backing up the car on the roadside when I accidentally hit a parked car behind me. I had to wait for a long time to speak to the owner, which made me feel anxious.', \"I was hoping to get promoted this year, but another coworker got it instead. It's really disappointing.\"]\n"
     ]
    }
   ],
   "source": [
    "paraphrases = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "result = []\n",
    "\n",
    "for sentence in paraphrases.split(\"\\n\"):\n",
    "    if sentence.__contains__(\":\"):\n",
    "        result.append(sentence.split(\":\")[1].strip())\n",
    "\n",
    "pprint(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
