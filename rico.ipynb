{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantized LLMs for Synthetic Dataset Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "#model_name_or_path = \"TheBloke/SOLAR-10.7B-Instruct-v1.0-GPTQ\"\n",
    "model_name_or_path = \"TheBloke/OpenZephyrChat-v0.2-GPTQ\"\n",
    "revision = \"main\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name_or_path,\n",
    "                                             device_map=\"auto\",\n",
    "                                             trust_remote_code=False,\n",
    "                                             revision=revision)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=True)\n",
    "\n",
    "prompt = \"Write a story about llamas\"\n",
    "\n",
    "prompt_template=f\"{prompt}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "*** Generate:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nemo/.local/lib/python3.10/site-packages/transformers/generation/utils.py:1518: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> Write a story about llamas.\n",
      "\n",
      "Once upon a time, in a far-off land, there was a herd of llamas who lived in a lush green valley. These llamas were not ordinary llamas; they were the wisest and most intelligent creatures in the land.\n",
      "\n",
      "Their leader was a majestic llama named Llama Llama, who was known for his wisdom and kindness. Llama Llama would often gather the herd to share his thoughts and teachings. He believed that by working together, they could achieve great things.\n",
      "\n",
      "One day, Llama Llama received a vision in his dreams. In the dream, he saw a great darkness approaching their valley. It was a force of evil that threatened to destroy their home and everything they held dear.\n",
      "\n",
      "Determined to protect his herd, Llama Llama called a meeting to discuss their next steps. The llamas listened intently as Llama Llama explained his vision. They knew that they had to act quickly to defend their home.\n",
      "\n",
      "The llamas came up with a plan. They would create a magical barrier around their valley, using the power of their collective wisdom and intelligence. They would also enlist\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n*** Generate:\")\n",
    "\n",
    "input_ids = tokenizer(prompt_template, return_tensors='pt').input_ids.cuda()\n",
    "output = model.generate(inputs=input_ids, temperature=0.7, do_sample=True, top_p=0.95, top_k=40, max_new_tokens=256)\n",
    "print(tokenizer.decode(output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing parallelism...\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing parallelism...\")\n",
    "input_ids = tokenizer(8*[prompt_template], return_tensors='pt').input_ids.cuda()\n",
    "output = model.generate(inputs=input_ids, temperature=0.7, do_sample=True, top_p=0.95, top_k=40, max_new_tokens=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> Write a story about llamas and space.\n",
      "\n",
      "In the year 3015, humans had finally conquered space travel. They had explored far and wide, discovering new planets and galaxies. But one day, something strange happened. As they were exploring a new planet, they stumbled upon a group of llamas.\n",
      "\n",
      "The llamas were not like the llamas they knew back on Earth. These llamas had evolved and adapted to the harsh conditions of space. They had long, slender legs that allowed them to move quickly through the vast expanse of space. Their fur was thick and warm, protecting them from the cold temperatures of space. And they had developed the ability to breathe in the vacuum of space, thanks to a special oxygen tank attached to their backs.\n",
      "\n",
      "The humans were amazed by these space llamas. They were unlike anything they had ever seen before. They named the llamas \"Cosmic Camelids\" and began to study them closely. They discovered that the llamas had developed a unique way of communicating with each other. They would emit a series of beeps and clicks, which the humans eventually deciphered as a form of language.\n",
      "\n",
      "As the humans studied the Cosmic Camelids, they began to learn more about the galaxy they were exploring. They discovered that the llamas had their own civilization, complete with cities, technology, and a complex social structure. The llamas were peaceful creatures, and they welcomed the humans with open arms.\n",
      "\n",
      "The humans and llamas worked together to explore the galaxy, sharing their knowledge and resources. They visited other planets and discovered new wonders, from floating gardens to sentient clouds. They also faced many challenges, from hostile alien species to the dangers of space travel itself.\n",
      "\n",
      "But through it all, the humans and llamas remained steadfast in their friendship and partnership. They had found a kindred spirit in each other, and they knew that together, they could conquer anything.\n",
      "\n",
      "As the years passed, the humans and llamas continued to explore the galaxy, always pushing the boundaries of what was possible. They had discovered that the universe was a vast and wondrous place, full of mysteries and wonders waiting to be explored. And they knew that as long as they had each other, they could face any challenge that came their way.\n",
      "\n",
      "In the end, the humans and llamas became known as the \"Galactic Explorers,\" a team of intrepid adventurers\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(output[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "#checkpoint = \"t5-base\"\n",
    "checkpoint = \"t5-small\"\n",
    "#checkpoint = \"facebook/bart-base\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(pretrained_model_name_or_path=checkpoint)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "The Inflation Reduction Act lowers prescription drug costs, health care costs, and energy costs. \n",
    "It's the most aggressive action on tackling the climate crisis in American history, which will lift up American workers and create good-paying, union jobs across the country. \n",
    "It'll lower the deficit and ask the ultra-wealthy and corporations to pay their fair share. \n",
    "And no one making under $400,000 per year will pay a penny more in taxes.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer(f\"summarize: {text}\", return_tensors=\"pt\").input_ids\n",
    "decoder_ids = tokenizer(\"\", return_tensors=\"pt\").input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.generate(input_ids=input_ids, max_new_tokens=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,     8,    16,    89,  6105,  4709,  1810,  1364,     7,  7744,\n",
       "          2672,  1358,     6,   533,   124,  1358,     6,    11,   827,  1358,\n",
       "             3,     5,    34,    31,     7,     8,   167,  8299,  1041,    30,\n",
       "             3, 26074,     8,  3298,  5362,    16, 10211,   892,     3,     5,\n",
       "            34,    56,   987,     8,  6173,    18,  1123,   138,   189,    63,\n",
       "            11, 11711,    12,   726,    70,  2725,   698,     3,     5,     1]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"the inflation reduction act lowers prescription drug costs, health care costs, and energy costs. it's the most aggressive action on tackling the climate crisis in american history. it will ask the ultra-wealthy and corporations to pay their fair share.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarization Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "billsum = load_dataset(path=\"billsum\", split=\"ca_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'The people of the State of California do enact as follows:\\n\\n\\nSECTION 1.\\nChapter 2.92 (commencing with Section 1001.85) is added to Title 6 of Part 2 of the Penal Code, to read:\\nCHAPTER  2.92. Law Enforcement Assisted Diversion (LEAD) Pilot Program\\n1001.85.\\n(a) The Law Enforcement Assisted Diversion (LEAD) pilot program is hereby established. The purpose of the LEAD program is to improve public safety and reduce recidivism by increasing the availability and use of social service resources while reducing costs to law enforcement agencies and courts stemming from repeated incarceration.\\n(b) LEAD pilot programs shall be consistent with the following principles, implemented to address and reflect the priorities of the community in which the program exists:\\n(1) Providing intensive case management services and an individually tailored intervention plan that acts as a blueprint for assisting LEAD participants.\\n(2) Prioritizing temporary and permanent housing that includes individualized supportive services, without preconditions of drug or alcohol treatment or abstinence from drugs or alcohol.\\n(3) Employing human and social service resources in coordination with law enforcement in a manner that improves individual outcomes and community safety, and promotes community wellness.\\n(4) Participation in LEAD services shall be voluntary throughout the duration of the program and shall not require abstinence from drug or alcohol use as a condition of continued participation.\\n1001.86.\\n(a) The LEAD program shall be administered by the Board of State and Community Corrections.\\n(b) The board shall award grants, on a competitive basis, to up to three jurisdictions as authorized by this chapter. The board shall establish minimum standards, funding schedules, and procedures for awarding grants, which shall take into consideration, but not be limited to, all of the following:\\n(1) Information from the applicant demonstrating a clear understanding of the program’s purpose and the applicant’s willingness and ability to implement the LEAD program as described in this chapter.\\n(2) Key local partners who would be committed to, and involved in, the development and successful implementation of a LEAD program, including, but not limited to, balanced representation from law enforcement agencies, prosecutorial agencies, public defenders and defense counsel, public health and social services agencies, case management service providers, and any other entities identified by the applicant as integral to the successful implementation of a LEAD program in the jurisdiction.\\n(3) The jurisdiction’s capacity and commitment to coordinate social services, law enforcement efforts, and justice system decisionmaking processes, and to work to ensure that the discretionary decisions made by each participant in the administration of the program operates in a manner consistent with the purposes of this chapter.\\n(c) Successful grant applicants shall collect and maintain data pertaining to the effectiveness of the program as indicated by the board in the request for proposals.\\n1001.87.\\n(a) LEAD programs funded pursuant to this chapter shall consist of a strategy of effective intervention for eligible participants consistent with the following gateways to services:\\n(1) Prebooking referral. As an alternative to arrest, a law enforcement officer may take or refer a person for whom the officer has probable cause for arrest for any of the offenses in subdivision (b) to a case manager to be screened for immediate crisis services and to schedule a complete assessment intake interview. Participation in LEAD diversion shall be voluntary, and the person may decline to participate in the program at any time. Criminal charges based on the conduct for which a person is diverted to LEAD shall not be filed, provided that the person finishes the complete assessment intake interview within a period set by the local jurisdictional partners, but not to exceed 30 days after the referral.\\n(2) Social contact referral. A law enforcement officer may refer an individual to LEAD whom he or she believes is at high risk of arrest in the future for any of the crimes specified in subdivision (b), provided that the individual meets the criteria specified in this paragraph and expresses interest in voluntarily participating in the program. LEAD may accept these referrals if the program has capacity after responding to prebooking diversion referrals described in paragraph (1). All social contact referrals to LEAD shall meet the following criteria:\\n(A) Verification by law enforcement that the individual has had prior involvement with low-level drug activity or prostitution. Verification shall consist of any of the following:\\n(i) Criminal history records, including, but not limited to, prior police reports, arrests, jail bookings, criminal charges, or convictions indicating that he or she was engaged in low-level drug or prostitution activity.\\n(ii) Law enforcement has directly observed the individual’s low-level drug or prostitution activity on prior occasions.\\n(iii) Law enforcement has a reliable basis of information to believe that the individual is engaged in low-level drug or prostitution activity, including, but not limited to, information provided by another first responder, a professional, or a credible community member.\\n(B) The individual’s prior involvement with low-level drug or prostitution activity occurred within the LEAD pilot program area.\\n(C) The individual’s prior involvement with low-level drug or prostitution activity occurred within 24 months of the date of referral.\\n(D) The individual does not have a pending case in drug court or mental health court.\\n(E) The individual is not prohibited, by means of an existing no-contact order, temporary restraining order, or antiharassment order, from making contact with a current LEAD participant.\\n(b) The following offenses are eligible for either prebooking diversion, social contact referral, or both:\\n(1) Possession for sale or transfer of a controlled substance or other prohibited substance where the circumstances indicate that the sale or transfer is intended to provide a subsistence living or to allow the person to obtain or afford drugs for his or her own consumption.\\n(2) Sale or transfer of a controlled substance or other prohibited substance where the circumstances indicate that the sale or transfer is intended to provide a subsistence living or to allow the person to obtain or afford drugs for his or her own consumption.\\n(3) Possession of a controlled substance or other prohibited substance.\\n(4) Being under the influence of a controlled substance or other prohibited substance.\\n(5) Being under the influence of alcohol and a controlled substance or other prohibited substance.\\n(6) Prostitution pursuant to subdivision (b) of Section 647.\\n1001.88.\\n(a) Services provided pursuant to this chapter may include, but are not limited to, case management, housing, medical care, mental health care, treatment for alcohol or substance use disorders, nutritional counseling and treatment, psychological counseling, employment, employment training and education, civil legal services, and system navigation. Grant funding may be used to support any of the following:\\n(1) Project management and community engagement.\\n(2) Temporary services and treatment necessary to stabilize a participant’s condition, including necessary housing.\\n(3) Outreach and direct service costs for services described in this section.\\n(4) Civil legal services for LEAD participants.\\n(5) Dedicated prosecutorial resources, including for coordinating any nondiverted criminal cases of LEAD participants.\\n(6) Dedicated law enforcement resources, including for overtime required for participation in operational meetings and training.\\n(7) Training and technical assistance from experts in the implementation of LEAD in other jurisdictions.\\n(8) Collecting and maintaining the data necessary for program evaluation.\\n(b) The board shall contract with a nonprofit research entity, university, or college to evaluate the effectiveness of the LEAD program. The evaluation design shall include measures to assess the cost-benefit outcomes of LEAD programs compared to booking and prosecution, and may include evaluation elements such as comparing outcomes for LEAD participants to similarly situated offenders who are arrested and booked, the number of jail bookings, total number of jail days, the prison incarceration rate, subsequent felony and misdemeanor arrests or convictions, and costs to the criminal justice and court systems. Savings will be compared to costs of LEAD participation. By January 1, 2020 a report of the findings shall be submitted to the Governor and the Legislature pursuant to Section 9795 of the Government Code.\\n(c) The board may contract with experts in the implementation of LEAD in other jurisdictions for the purpose of providing technical assistance to participating jurisdictions.\\n(d) The board shall not spend more than 5 percent annually of the moneys allocated to the program for its administrative costs, excluding the contracts authorized in subdivisions (b) and (c).\\n1001.89.\\nThis chapter shall remain in effect only until January 1, 2020, and as of that date is repealed, unless a later enacted statute, that is enacted before January 1, 2020, deletes or extends that date.\\nSECTION 1.\\nChapter 2.92 (commencing with Section 1001.85) is added to Title 6 of Part 2 of the\\nPenal Code\\n, to read:\\n2.92.\\nLaw Enforcement Assisted Diversion\\n1001.85.\\n(a)The Board of State and Community Corrections shall approve three counties for the establishment of a Law Enforcement Assisted Diversion (LEAD) pilot program. Interested counties shall submit applications to the board, including information on the manner in which the program will operate in that county, as required by the board.\\n(b)LEAD pilot programs shall include both of the following:\\n(1)Authorization for designated peace officers to take a person for whom the officer has probable cause for arrest for any of the following offenses to a drug treatment facility or program for treatment, including detoxification and related services in lieu of that arrest:\\n(A)Possession for sale or transfer of a controlled substance or other prohibited substance where the circumstances indicate that the sale or transfer is intended to provide a subsistence living or to allow the person to obtain or afford drugs for his or her own consumption.\\n(B)Sale or transfer of a controlled substance or other prohibited substance where the circumstances indicate that the sale or transfer is intended to provide a subsistence living or to allow the person to obtain or afford drugs for his or her own consumption.\\n(C)Possession of a controlled substance or other prohibited substance.\\n(D)Being under the influence of a controlled substance or other prohibited substance.\\n(E)Being under the influence of alcohol and a controlled substance or other prohibited substance.\\n(2)Authorization for designated peace officers to take a person for whom the officer has probable cause for arrest for prostitution pursuant to subdivision (b) of Section 647, to an agency or entity that will provide services to that person in lieu of that arrest. Services pursuant to this paragraph may include, but are not limited to, housing, medical care, child care, treatment for alcohol or substance abuse, nutritional counseling and treatment, psychological counseling, employment, and employment training and education.\\n(c)The Legislature finds and declares that a program similar to the LEAD program has been demonstrated in Seattle, Washington to lower recidivism of participants, increase cooperation by participants in treatment and related programs, and significantly reduce law enforcement and court costs.',\n",
       " 'summary': 'Existing law authorizes a county to establish a pretrial diversion program for defendants who have been charged with a misdemeanor offense and authorizes other diversion programs, including for defendants with cognitive developmental disabilities, defendants in nonviolent drug cases, and traffic violations.\\nThis bill would require the Board of State and Community Corrections to approve three counties for the establishment of a Law Enforcement Assisted Diversion (LEAD) pilot program. The bill would require the LEAD pilot programs to authorize designated officers to take a person for whom the officer has probable cause for arrest for specified controlled substances offenses, including possession of a controlled substance or other prohibited substance, or prostitution, to treatment programs and services in lieu of that arrest.\\nThis bill, until January 1, 2020, would establish the Law Enforcement Assisted Diversion (LEAD) pilot program, to be administered by the Board of State and Community Corrections, to improve public safety and reduce recidivism by increasing the availability and use of social service resources while reducing costs to law enforcement agencies and courts stemming from repeated incarceration. The bill would require the board to award grants, on a competitive basis, to up to 3 jurisdictions to establish LEAD programs and would require the board to establish minimum standards, funding schedules, and procedures for awarding grants. The bill would establish requirements for referral of people who may be arrested for, or who have a history of, low-level drug offenses or prostitution, as defined, to social services in lieu of prosecution. The bill would require the board to contract with a nonprofit research entity, university, or college to evaluate the effectiveness of the LEAD program and submit a report of the findings to the Governor and the Legislature by January 1, 2020.',\n",
       " 'title': 'An act to add\\nand repeal\\nChapter 2.92 (commencing with Section 1001.85) of Title 6 of Part 2 of the Penal Code, relating to diversion.'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "billsum = billsum.train_test_split(test_size=0.2)\n",
    "billsum[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BatchEncoding\n",
    "\n",
    "prefix = \"summarize: \"\n",
    "\n",
    "\n",
    "def preprocess_function(examples) -> BatchEncoding:\n",
    "    inputs = [prefix + doc for doc in examples[\"text\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=1024, truncation=True)\n",
    "\n",
    "    labels = tokenizer(text_target=examples[\"summary\"], max_length=128, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17e547b67eec45c6b9f6fd90253ee464",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/989 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b451e6a7d4f41b1b8b0ba0445b9afca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/248 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_billsum = billsum.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "rouge = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "\n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "if model is None:\n",
    "    print(\"new model...\")\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='496' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 31/496 00:17 < 04:46, 1.62 it/s, Epoch 0.24/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5305/478821036.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m )\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1553\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1555\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1556\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1557\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1859\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccumulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1860\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1862\u001b[0m                 if (\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2732\u001b[0m                 \u001b[0mscaled_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2733\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2734\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2736\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_accumulation_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/accelerate/accelerator.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   1985\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1986\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1987\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1988\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1989\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"local\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=6,\n",
    "    per_device_eval_batch_size=6,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=4,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_billsum[\"train\"],\n",
    "    eval_dataset=tokenized_billsum[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
